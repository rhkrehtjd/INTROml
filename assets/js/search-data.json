{
  
    
        "post0": {
            "title": "2022/1/1/SAT(HappyNewYear)",
            "content": "datail-review 해보자 . feature_names = 높이,가로 길이 이런 것들, data = 각 featuredml 값들, target = 0,1,2...예를 들면 붓꽃의 이름을 대용한 것, target_names = 각 target이 가리키는 이름이 무엇인지? | . . model_selection 모듈은 학습 데이터와 테스트 데이터 세트를 분리하거나 교차 검증 분할 및 평가, 그리고 Estimator의 하이퍼 파라미터를 튜닝하기 위한 다양한 함수와 클래스를 제공, 전체 데이터를 학습 데이터와 테스트 데이터 세트로 분리해주는 train_test_split()부터 살펴보자 . from sklearn.datasets import load_iris from sklearn.tree import DecisionTreeClassifier from sklearn.metrics import accuracy_score iris=load_iris() # 붓꽃 데이터 세트 로딩 dt_clf=DecisionTreeClassifier() train_data=iris.data # 데이터 세트에서 feature만으로 구성된 데이터가 ndarray train_label=iris.target # 데이터 세트에서 label 데이터 dt_clf.fit(train_data, train_label) # 학습 수행중 pred=dt_clf.predict(train_data) # 예측 수행중 // 그런데 학습때 사용했던 train_data를 사용했음 -&gt; 예측도 1 나올 것 print(&#39;예측도: &#39;,accuracy_score(train_label,pred)) . 예측도: 1.0 . 정확도가 100% 나왔음 $ to$ 이미 학습한 학습 데이터 세트를 기반으로 예측했기 때문. 답을 알고 있는데 같은 문제를 낸 것이나 마찬가지 | 따라서 예측을 수행하는 데이터 세트는 학습을 수행한 학습용 데이터 세트가 아닌 전용의 테스트 데이터 세트여야 함. | . from sklearn.model_selection import train_test_split . dt_clf=DecisionTreeClassifier() iris=load_iris() # train_test_split()의 반환값은 튜플 형태이다. 순차적으로 네가지 요소들을 반환한다 X_train,X_test,y_train,y_test=train_test_split(iris.data, iris.target,test_size=0.3,random_state=121) dt_clf.fit(X_train,y_train) pred = dt_clf.predict(X_test) print(&#39;예측 정확도: {:.4f}&#39;.format(accuracy_score(y_test,pred))) . 예측 정확도: 0.9556 . . 지금까지의 방법은 모델이 학습 데이터에만 과도하게 최적화되어, 실제 예측을 다른 데이터로 수행할 경우에는 예측 성능이 과도하게 떨어지는 과적합이 발생할 수 있다. 즉 해당 테스트 데이터에만 과적합되는 학습 모델이 만들어져 다른 테스트용 데이터가들어올 경우에는 성능이 저하된다. $ to$ 개선하기 위해 교차검증을 이용해 다양한 학습과 평가를 수행해야 한다. . 교차검증? . : 본고사 치르기 전, 여러 모의고사를 치르는 것. 즉 본고사가 테스트 데이터 세트에 대해 평가하는 것이라면 모의고사는 교차 검증에서 많은 학습과 검증 세트에서 알고리즘 학습과 평가를 수행하는 것. . : 학습 데이터 세트를 검증 데이터 세트와 학습 데이터 세트로 분할하여 수행한 뒤, 모든 학습/검증 과정이 완료된 후 최종적으로 성능을 평가하기 위해 테스트 데이터 세트를 마련함. . K fold 교차 검증? . : K개의 데이터 폴드 세트를 만들어서 K번만큼 각 폴드 세트에 학습과 검증, 평가를 반복적으로 수행 / 개괄적 과정은 교재 104 참고 . 실습해보자 | . import numpy as np . from sklearn.datasets import load_iris from sklearn.tree import DecisionTreeClassifier from sklearn.metrics import accuracy_score from sklearn.model_selection import KFold # 위에서는 trian_test_split을 import했었음 iris=load_iris() # 붓꽃 데이터 세트 로딩 features=iris.data label=iris.target dt_clf=DecisionTreeClassifier(random_state=156) kfold=KFold(n_splits=5) # KFold 객체 생성 cv_accuracy=[] # fold set별 정확도를 담을 리스트 객체 생성 print(&#39;붓꽃 데이터 세트 크기:&#39;,features.shape[0]) . 붓꽃 데이터 세트 크기: 150 . . kfold=KFold(n_splits=5) . 로 KFold객체를 생성했으니 객체의 split()을 호출해 전체 붓꽃 데이터를 5개의 fold 데이터 세트로 분리하자. 붓꽃 데이터 세트 크기가 150개니 120개는 학습용, 30개는 검증 테스트 데이터 세트이다. . n_iter=0 for train_index,test_index in kfold.split(features): # kfold.split()으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터 추출 X_train, X_test = features[train_index], features[test_index] y_train, y_test = label[train_index], label[test_index] # 학습 및 예측 dt_clf.fit(X_train, y_train) pred = dt_clf.predict(X_test) n_iter+=1 # 반복 시마다 정확도 측정 accuracy = np.round(accuracy_score(y_test,pred),4) train_size = X_train.shape[0] test_size = X_test.shape[0] print(&#39; n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기 :{2}, 검증 데이터 크기 :{3}&#39;.format(n_iter,accuracy,train_size,test_size)) print(&#39;#{0} 검증 세트 인덱스:{1}&#39;.format(n_iter, test_index)) cv_accuracy.append(accuracy) # 개별 iteration별 정확도를 합하여 평균 정확도 계산 print(&#39; n *Conclusion* 평균 검증 정확도:&#39;, np.mean(cv_accuracy)) . #1 교차 검증 정확도 :1.0, 학습 데이터 크기 :120, 검증 데이터 크기 :30 #1 검증 세트 인덱스:[ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29] #2 교차 검증 정확도 :0.9667, 학습 데이터 크기 :120, 검증 데이터 크기 :30 #2 검증 세트 인덱스:[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59] #3 교차 검증 정확도 :0.8667, 학습 데이터 크기 :120, 검증 데이터 크기 :30 #3 검증 세트 인덱스:[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89] #4 교차 검증 정확도 :0.9333, 학습 데이터 크기 :120, 검증 데이터 크기 :30 #4 검증 세트 인덱스:[ 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119] #5 교차 검증 정확도 :0.7333, 학습 데이터 크기 :120, 검증 데이터 크기 :30 #5 검증 세트 인덱스:[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149] *Conclusion* 평균 검증 정확도: 0.9 . . 교차 검증시마다 검증 세트의 인덱스가 달라짐을 알 수 있다. . | 검증세트 인덱스를 살펴보면 104p에서 설명한 그림의 설명과 유사함 . | . . Stratified K 폴드 . : 불균형한 분포도를가진 레이블(결정 클래스) 데이터 집합을 위한 K 폴드 방식이다. 불균형한 분포도를 가진 레이블 데이터 집합은 특정 레이블 값이 특이하게 많거나 또는 적어서 분포가 한쪽으로 치우치는 것을 말함 . 가령 대출 사기 데이터를 예측한다고 가정해보자, 이 데이터 세트는 1억건이고 수십개의 feature와 대출 사기 여부를 뜻하는 label(정상 대출0, 대출사기 : 1)로 구성돼 있다. K폴드로 랜덤하게 학습 및 테스트 세트의 인덱스를 고르더라도 레이블 값인 0과1의 비율을 제대로 반영하지 못하게 됨. 따라서 원본 데이터와 유사한 대출 사기 레이블 값의 분포를 학습/테스트 세트에도 유지하는 게 매우 중요 . Stratified K 폴드는 이처럼 K폴드가 레이블 데이터 집합이 원본 데이터 집합의 레이블 분포를 학습 및 테스트 세트에 제대로 분배하지 못하는 경우의 문제를 해결해줌 | . 붓꽃 데이터 세트를 DataFrame으로 생성하고 레이블 값의 분포도를 먼저 확인해보자 . import pandas as pd iris=load_iris() iris_df=pd.DataFrame(data=iris.data,columns=iris.feature_names) iris_df[&#39;label&#39;]=iris.target print(iris_df[&#39;label&#39;].value_counts(),&#39; n&#39;) . 0 50 1 50 2 50 Name: label, dtype: int64 . label값은 모두 50개로 분배되어 있음 | . kfold=KFold(n_splits=3) n_iter=0 for train_index, test_index in kfold.split(iris_df): n_iter+=1 label_train = iris_df[&#39;label&#39;].iloc[train_index] label_test=iris_df[&#39;label&#39;].iloc[test_index] print(&#39;## 교차 검증: {}&#39;.format(n_iter)) print(&#39;학습 레이블 데이터 분포: n&#39;, label_train.value_counts()) print(&#39;검증 레이블 데이터 분포: n&#39;, label_test.value_counts()) print(&#39;&#39;) . ## 교차 검증: 1 학습 레이블 데이터 분포: 1 50 2 50 Name: label, dtype: int64 검증 레이블 데이터 분포: 0 50 Name: label, dtype: int64 ## 교차 검증: 2 학습 레이블 데이터 분포: 0 50 2 50 Name: label, dtype: int64 검증 레이블 데이터 분포: 1 50 Name: label, dtype: int64 ## 교차 검증: 3 학습 레이블 데이터 분포: 0 50 1 50 Name: label, dtype: int64 검증 레이블 데이터 분포: 2 50 Name: label, dtype: int64 . 교차 검증 시마다 3개의 폴드 세트로 만들어지는 학습 레이블과 검증 레이블이 완전히 다른 값으로 추출되었다. 예를 들어 첫번째 교차 검증에서는 학습 레이블의 1,2값이 각각 50개가 추출되었고 검증 레이블의 0값이 50개 추출되었음, 즉 학습레이블은 1,2 밖에 없으므로 0의 경우는 전혀 학습하지 못함. 반대로 검증 레이블은 0밖에 없으므로 학습 모델은 절대 0을 예측하지 못함. 이런 유형으로 교차 검증 데이터 세트를 분할하면 검증 예측 정확도는 0이 될 수밖에 없다. | . StratifiedKFold는 이렇게 KFold로 분할된 레이블 데이터 세트가 전체 레이블 값의 분포도를 반영하지 못하는 문제를 해결함. | . . 실습해보자 . from sklearn.model_selection import StratifiedKFold skf=StratifiedKFold(n_splits=3) n_iter=0 # split 메소드에 인자로 feature데이터 세트뿐만 아니라 레이블 데이터 세트도 반드시 넣어줘야함 for train_index,test_index in skf.split(iris_df,iris_df[&#39;label&#39;]): n_iter+=1 label_train=iris_df[&#39;label&#39;].iloc[train_index] label_test=iris_df[&#39;label&#39;].iloc[test_index] print(&#39;## 교차검증: {}&#39;.format(n_iter)) print(&#39;학습 레이블 데이터 분포: n&#39;, label_train.value_counts()) print(&#39;검증 레이블 데이터 분포: n&#39;, label_test.value_counts()) print(&#39;--&#39;) . ## 교차검증: 1 학습 레이블 데이터 분포: 2 34 0 33 1 33 Name: label, dtype: int64 검증 레이블 데이터 분포: 0 17 1 17 2 16 Name: label, dtype: int64 -- ## 교차검증: 2 학습 레이블 데이터 분포: 1 34 0 33 2 33 Name: label, dtype: int64 검증 레이블 데이터 분포: 0 17 2 17 1 16 Name: label, dtype: int64 -- ## 교차검증: 3 학습 레이블 데이터 분포: 0 34 1 33 2 33 Name: label, dtype: int64 검증 레이블 데이터 분포: 1 17 2 17 0 16 Name: label, dtype: int64 -- . 학습 레이블과 검증 레이블 데이터 값의 분포도가 동일하게 할당됐음을 알 수 있다. 이렇게 분할이 되어야 레이블 값 0,1,2를 모두 학습할 수 있고 이에 기반해 검증을 수행할 수 있다. | . 이제 StratifiedKFold를 이용해 붓꽃 데이터를 교차 검증해보자 | . df_clf=DecisionTreeClassifier(random_state=156) skfold=StratifiedKFold(n_splits=3) n_iter=3 cv_accuracy=[] # StratifiedKFol의 split() 호출시 반드시 레이블 데이터 세트도 추가 입력 필요 for train_index, test_ondex in skfold.split(features, label): # split()으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터 추출 X_train,X_test=features[train_index],features[test_index] y_train,y_test=label[train_index], label[test_index] # 학습 및 예측 df_clf.fit(X_train,y_train) pred=dt_clf.predict(X_test) # 반복시마다 정확도 측정 n_iter+=1 accuracy=np.around(accuracy_score(y_test,pred),4) train_size=X_train.shape[0] test_size = X_test.shape[0] print(&#39; n#{} 교차 검증 정확도 : {}, 학습 데이터 크기 : {}, 검증 데이터 크기 : {}&#39;.format(n_iter,accuracy,train_size,test_size)) print(&#39;#{} 검증 세트 인덱스: {}&#39;.format(n_iter, test_index)) cv_accuracy.append(accuracy) # 교차 검증별 정확도 및 평균 정확도 계산 print(&#39; n## 교차 검증별 정확도:&#39;, np.around(cv_accuracy,4)) print(&#39;## 평균 검증 정확도:&#39;,np.mean(cv_accuracy)) . #4 교차 검증 정확도 : 0.92, 학습 데이터 크기 : 100, 검증 데이터 크기 : 50 #4 검증 세트 인덱스: [ 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149] ## 교차 검증별 정확도: [0.92] ## 평균 검증 정확도: 0.92 #5 교차 검증 정확도 : 0.92, 학습 데이터 크기 : 100, 검증 데이터 크기 : 50 #5 검증 세트 인덱스: [ 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149] ## 교차 검증별 정확도: [0.92 0.92] ## 평균 검증 정확도: 0.92 #6 교차 검증 정확도 : 0.92, 학습 데이터 크기 : 100, 검증 데이터 크기 : 50 #6 검증 세트 인덱스: [ 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149] ## 교차 검증별 정확도: [0.92 0.92 0.92] ## 평균 검증 정확도: 0.92 . . &#44368;&#52264; &#44160;&#51613;&#51012; &#48372;&#45796; &#44036;&#54200;&#54616;&#44172; - cross_val_score() . from sklearn.tree import DecisionTreeClassifier from sklearn.model_selection import cross_val_score,cross_validate from sklearn.datasets import load_iris iris_data=load_iris() dt_clf = DecisionTreeClassifier(random_state=156) data= iris_data.data label=iris_data.target # 성능 지표는 정확도 (accuracy), 교차 검증 세트는 3개 scores = cross_val_score(dt_clf, data, label, scoring=&#39;accuracy&#39;, cv=3) print(&#39;교차 검증별 정확도: &#39;,np.round(scores,4)) print(&#39;평균 검증 정확도: &#39;,np.round(np.mean(scores),4)) . 교차 검증별 정확도: [0.98 0.94 0.98] 평균 검증 정확도: 0.9667 . cv로 지정된 횟수만큼 scoring 파라미터로 지정된 평가지표로 평가 결과값을 배열로 반환 | . . GridSearchCV - &#44368;&#52264; &#44160;&#51613;&#44284; &#52572;&#51201; &#54616;&#51060;&#54140; &#54028;&#46972;&#48120;&#53552; &#53916;&#45789;&#51012; &#46041;&#49884;&#50640; . 하이퍼 파라미터? 머신러닝 알고리즘을 구성하는 주요 구성 요소이며, 이 값을 조정해 알고리즘의 예측 성능을 개선할 수 있음 | . from sklearn.datasets import load_iris from sklearn.tree import DecisionTreeClassifier from sklearn.model_selection import GridSearchCV # 데이터를 로딩하고 학습 데이터와 테스트 데이터 분리 iris_data = load_iris() X_train, X_test, y_train, y_test = train_test_split(iris_data.data,iris_data.target, test_size=0.2, random_state=121) dtree= DecisionTreeClassifier() # 파라미터를 딕셔너리 형태로 설정 parameters = {&#39;max_depth&#39; : [1,2,3], &#39;min_samples_split&#39; : [2,3]} import pandas as pd # param_grid의 하이퍼 파라미터를 3개의 train, test set fold로 나누어 테스트 수행 설정 # rifit=True가 default이며, 이때 가장 젛은 파라미터 설정으로 재학습시킴 grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True) # 붓꽃 학습 데이터로 param_grid의 하이퍼 파라미터를 순차적으로 학습/평가 grid_dtree.fit(X_train,y_train) #GridSearchCV 결과를 추출해 DataFrame으로 변환 scores_df = pd.DataFrame(grid_dtree.cv_results_) scores_df[[&#39;params&#39;,&#39;mean_test_score&#39;,&#39;rank_test_score&#39;,&#39;split0_test_score&#39;,&#39;split1_test_score&#39;,&#39;split2_test_score&#39;]] . params mean_test_score rank_test_score split0_test_score split1_test_score split2_test_score . 0 {&#39;max_depth&#39;: 1, &#39;min_samples_split&#39;: 2} | 0.700000 | 5 | 0.700 | 0.7 | 0.70 | . 1 {&#39;max_depth&#39;: 1, &#39;min_samples_split&#39;: 3} | 0.700000 | 5 | 0.700 | 0.7 | 0.70 | . 2 {&#39;max_depth&#39;: 2, &#39;min_samples_split&#39;: 2} | 0.958333 | 3 | 0.925 | 1.0 | 0.95 | . 3 {&#39;max_depth&#39;: 2, &#39;min_samples_split&#39;: 3} | 0.958333 | 3 | 0.925 | 1.0 | 0.95 | . 4 {&#39;max_depth&#39;: 3, &#39;min_samples_split&#39;: 2} | 0.975000 | 1 | 0.975 | 1.0 | 0.95 | . 5 {&#39;max_depth&#39;: 3, &#39;min_samples_split&#39;: 3} | 0.975000 | 1 | 0.975 | 1.0 | 0.95 | . print(&#39;GridSearchCV 최적 파라미터:&#39;, grid_dtree.best_params_) print(&#39;GridSearchCV 최고 정확도:{:4f}&#39;.format(grid_dtree.best_score_)) . GridSearchCV 최적 파라미터: {&#39;max_depth&#39;: 3, &#39;min_samples_split&#39;: 2} GridSearchCV 최고 정확도:0.975000 . 인덱스 4,5rk rank_test_score가 1인 것으로 보아 공동 1위이며 예측 성능 1등을 의미함. | 열 4,5,6은 cv=3 이라서 열2는 그 세개의 평균을 의미 | . estimator = grid_dtree.best_estimator_ # GridSearchCV의 best_estimator_는 이미 최적 학습이 됐으므로 별도 학습이 필요없음 pred = estimator.predict(X_test) print(&#39;테스트 데이터 세트 정확도: {:.4f}&#39;.format(accuracy_score(y_test,pred))) . 테스트 데이터 세트 정확도: 0.9667 . 일반적으로 학습 데이터를 GridSearchCV를 이용해 최적 하이퍼 파라미터 튜닝을 수행한 뒤에 별도의 테스트 세트에서 이를 평가하는 것이 일반적인 머신 러닝 모델 적용 방법이다. | .",
            "url": "https://rhkrehtjd.github.io/INTROml/2021/12/31/intro.html",
            "relUrl": "/2021/12/31/intro.html",
            "date": " • Dec 31, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Machine Learning?",
            "content": "&#45936;&#51060;&#53552;&#50640; &#47784;&#45944;&#51012; &#47582;&#52632;&#45796; . 애플리케이션을 수정하지 않고도 데이터를 기반으로 패턴을 학습하고 결과를 예측하는 알고리즘 기법을 통칭 | . 데이터 기반으로 통계적인 신뢰도를 강화하고 예측 오류를 최소화하기 위한 다양한 수학적 기법을 적용해 데이터 내의 패턴을 스스로 인지하고 신뢰도 있는 예측 결과를 도출 | . 데이터를 관통하는 패턴을 학습, 이에 기반한 예측 수행 | . 모델을 맞춘다? 모델을 학습시키는 기법들에는 딥러닝, 나이브베이즈, 디시전트리 등이 있음, 모델을 맞추는 행위를 하지 않으면 이 모델은 어떤 문제도 해결할 수가 없음, 따라서 데이터를 모델에 맞추는 행위가 필요함 | . 따라서 이 데이터에 문제를 최대한 많이 맞출 수 있도록 모델을 최적화하여야 하는데 이렇게 최적화가 된 모델이 그 데이터에 해당된 문제를 해결할 수 있게 됨 | . 분류 :지도 학습(Supervised Learning), 비지도 학습(Un-supervised Learning), 강화 학습(Reinforcement Learning) 지도학습 $ to$ 분류(Classification)와 회귀(Regression)로 나눌 수 있음 . . data? Garbage In $ to$ Garbage Out : data도 질이 중요하다 | . 데이터를 이해하고 효율적으로 가공,처리,추출하여 최적의 데이터를 기반으로 알고리즘을 구동할 수 있도록 준비하는 능력 필요 | . . 만약 온도, 습도, 풍속을 정리해놓은 데이터가 있을 때 눈이 오는 여부를 다양한 기법으로 해결할 수 있음 . 1) 조건을 정해서 해결한다.(decision tree 등) . 2) 수식(가중치)으로 해결한다.(선형 회귀, 딥러닝 등) . 이러한 접근 방식을 통해서 가지고 있는 데이터를 50%정도만 해결했다면 이 접근 방식들은 썩 좋지 않은 방식일 것임 . 따라서 머신러닝을 학습한다는 것은 이 정답을 최대한 맞출 수 있도록 모델을 최대한 최적화한다는 의미임. 이렇게 가장 좋은 성능이 나올 수 있는 식과 조건을 찾아나가는 것을 기계가 스스로 하는 것을 머신러닝이라고 생각할 수도 있겠음. . . 딥러닝 등 머신러닝 기법들 전반적으로 공부할 필요가 있다 . 딥러닝 : 자연어와 이미지 처리에 강하다. 그렇지만 다른 과업처리에 있어서도 항상 우수한 결과를 도출해내는 것은 아니다. 대표적으로 KAGGLE에 있는 TITANIC자료에서 실제로 산 승객과 죽은 승객을 처리해내는 과업을 수행할 땐 딥러닝보다 머신러닝의 모델이 더 좋은 결과를 도출해냈음 | . &#44208;&#44397; &#47785;&#51201;&#51008; &#45936;&#51060;&#53552;&#47484; &#47784;&#45944;&#50640; &#52572;&#51201;&#54868; &#49884;&#53412;&#45716; &#44163;&#51060;&#45796; . 머신러닝 논문에 머신러닝 기법들간에 성능을 비교한 표도 있음. 즉, 머신러닝 기법들은 다양한 기법들이 있기 때문에 그 것들간의 차이점과, 각각의 알고리즘이 무엇을 최적화하려는 것인지의 관점에서 이해해보아야함 . . . &#54028;&#51060;&#50028; &#47672;&#49888;&#47084;&#45789; &#49373;&#53468;&#44228;&#47484; &#44396;&#49457;&#54616;&#45716; &#51452;&#50836; &#54056;&#53412;&#51648; . 머신러닝 패키지 : Scikit-Learn . | 행렬/ 선형대수/ 통계 패키지 : Numpy, SciPy . | 데이터 핸들링 : Pandas(Numpy는 행렬 기반의 데이터 처리에 특화) $ to$ 2차원 데이터 처리에 특화,Matplotlib . | 시각화 : matplotlib(너무 세분화 되어 있어서 익히기 어려움, 시각적인 면에서도 투박),Seaborn(matplotlib의 대안이 될 것) . | .",
            "url": "https://rhkrehtjd.github.io/INTROml/2021/12/28/intro.html",
            "relUrl": "/2021/12/28/intro.html",
            "date": " • Dec 28, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://rhkrehtjd.github.io/INTROml/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://rhkrehtjd.github.io/INTROml/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}