{
  
    
        "post0": {
            "title": "2021/12/31/FRI",
            "content": "Scikit-Learn :파이썬 머신러닝 라이브러리 중 가장 많이 사용되는 라이브러리 $ to$ 머신러닝을 위한 다양한 알고리즘과 편리한 프레임 워크, API를 제공 . import sklearn . &#48531;&#44867; &#54408;&#51333; &#50696;&#52769;&#54616;&#44592; . 붓꽃 데이터 세트로 붓꽃의 품종을 분류 . | 분류(Classification)는 대표적인 지도학습(Supervised Learning) 방법 중 하나 . | 지도학습은 학습을 위한 다양한 feature와 분류 결정값인 레이블 데이터로 모델을 학습한 뒤, 별도의 테스트 데이터 세트에서 미지의 레이블을 예측 . | 학습을 위해 주어진 데이터 세트를 학습 데이터 세트, 머신러닝 모델의 예측 성능을 평가하기 위해 별도로 주어진 데이터 세트를 테스트 데이터 세트라 함 . | . . sklearn.datasets내의 모듈은 사이킷런에서 자체적으로 제공하는 데이터 세트를 생성하는 모듈의 모임 . | sklearn.tree내의 모듈은 트리 기반 ML 알고리즘을 구현한 클래스의 모임 . | sklearn.model_selection은 학습 데이터와 검증 데이터, 예측 데이터로 데이터를 분리하거나 최적의 하이퍼 파라미터로 평가하기 위한 다양한 모듈의 모임 . | 하이퍼 파라미터 : 머신 러닝 알고리즘별로 최적의 학습을 위해 직접 입력하는 파라미터를 통칭, 하이퍼 파라미터를 통해 머신 러닝 알고리즘의 성능을 튜닝할 수 있다. . | . from sklearn.datasets import load_iris from sklearn.tree import DecisionTreeClassifier from sklearn.model_selection import train_test_split import pandas as pd . iris = load_iris() # 붓꽃 데이터 세트 로딩 . iris.keys() . dict_keys([&#39;data&#39;, &#39;target&#39;, &#39;frame&#39;, &#39;target_names&#39;, &#39;DESCR&#39;, &#39;feature_names&#39;, &#39;filename&#39;, &#39;data_module&#39;]) . iris_data = iris.data # iris 데이터 세트에서 feature만으로 구성된 데이터를 numpy로 로딩 . iris_label = iris.target # 데이터 세트에서 레이블(결정값) 데이터를 numpy로 로딩 . iris.target_names . array([&#39;setosa&#39;, &#39;versicolor&#39;, &#39;virginica&#39;], dtype=&#39;&lt;U10&#39;) . 붓꽃 데이터 세트를 자세히 보기 위해 DataFrame으로 변환 | . iris.feature_names . [&#39;sepal length (cm)&#39;, &#39;sepal width (cm)&#39;, &#39;petal length (cm)&#39;, &#39;petal width (cm)&#39;] . iris_df = pd.DataFrame(data=iris_data,columns=iris.feature_names) . iris_df . sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) . 0 5.1 | 3.5 | 1.4 | 0.2 | . 1 4.9 | 3.0 | 1.4 | 0.2 | . 2 4.7 | 3.2 | 1.3 | 0.2 | . 3 4.6 | 3.1 | 1.5 | 0.2 | . 4 5.0 | 3.6 | 1.4 | 0.2 | . ... ... | ... | ... | ... | . 145 6.7 | 3.0 | 5.2 | 2.3 | . 146 6.3 | 2.5 | 5.0 | 1.9 | . 147 6.5 | 3.0 | 5.2 | 2.0 | . 148 6.2 | 3.4 | 5.4 | 2.3 | . 149 5.9 | 3.0 | 5.1 | 1.8 | . 150 rows × 4 columns . iris_df[&#39;label&#39;]=iris_label . iris_df.head(3) . sepal length (cm) sepal width (cm) petal length (cm) petal width (cm) label . 0 5.1 | 3.5 | 1.4 | 0.2 | 0 | . 1 4.9 | 3.0 | 1.4 | 0.2 | 0 | . 2 4.7 | 3.2 | 1.3 | 0.2 | 0 | . feature : columns를 의미함 | label(결정값) : 0,1,2 세 가지 값응로 돼 있으며 순서대로 Setosa,versicolor,virginica 품종을 의미 | . . 학습용 데이터와 테스트용 데이터를 분리해보자 | . 학습용 데이터와 테스트용 데이터는 반드시 분리해야 함, 이를 위해 Scikit-learn에선 train_test_split() API를 제공, 해당 API를 이용하면 학습 데이터와 테스트 데이터를 test_size 파라미터 입력 값의 비율로 쉽게 분할함 | . 예를 들어보자, teat_size=0.2로 입력 파라미터를 설정하면 전체 데이터 중 테스트 데이터가 20%, 학습 데이터가 80%로 데이터를 분할함 | . X_train,X_test,y_train,y_test=train_test_split(iris_data,iris_label,test_size=0.2, random_state=11) . train_test_split의 첫 번째 파라미터인 iris_data는 feature 데이터 세트이며, 두 번째 파라미터인 iris_label은 Label 데이터 세트. random_state=11은 호출할 때마다 같은 학습/테스트용 데이터 세트를 생성하기 위해 주어지는 난수 발생 값. . | train_test_split은 호출 시 무작위로 데이터를 분리하므로 random_state를 지정하지 않으면 수행할 때마다 다른 학습/테스트 용 데이터를 만듦. . | X_train,X_test,y_train,y_test = 학습용 feature데이터 세트, 테스트용 feature데이터 세트, 학습용 레이블 데이터 세트, 테스트용 레이블 데이터 세트를 의미 . | . . 이제 이 데이터를 기반으로 머신 러닝 분류 알고리즘의 하나인 의사 결정 트리를 이용해 학습과 예측을 수행 . dt_clf=DecisionTreeClassifier(random_state=11) . dt_clf.fit(X_train,y_train) # 학습용 feature 데이터 세트와 학습용 레이블 데이터 세트를 입력해 학습 수행중 . DecisionTreeClassifier(random_state=11) . 학습 완료/ 예측을 수행해야하는데 학습 데이터가 아닌 다른 데이터를 이용해야 하며, 일반적으로 테스트 데이터 세트를 이용함 | . pred=dt_clf.predict(X_test) # 예측 수행 중 # 예측 label data set . 예측 성능 평가, 여러 평가 방법 중 정확도를 측정해보자. 정확도는 예측 결과가 실제 레이블 값과 얼마나 정확하게 맞는지를 평가하는 지표 | . from sklearn.metrics import accuracy_score print(&#39;예측 정확도: {:.4f}&#39;.format(accuracy_score(y_test,pred))) . 예측 정확도: 0.9333 . 학습한 의사 결정 트리의 알고리즘 예측 정확도가 약 93.33% | . . Conclusion . 1) 데이터 세트 분리 : 데이터를 학습 데이터와 테스트 데이터로 분리 2) 모델 학습 : 학습 데이터를 기반으로 ML 알고리즘을 적용해 모델을 학습 3) 예측 수행 : 학습된 ML 모델을 이용해 테스트 데이터의 분류(즉, 붓꽃 종류)를 예측 4) 평가 : 이렇게 예측된 결과값과 테스트 데이터의 실제 결과값을 비교해 ML 모델 성능을 평가 . . 간단한 실습을 해보았으니 전체적 틀을 review해보자 . ML 모델 학습을 위해서 fit(), 학습된 모델의 예측을 위해 predict()를 사용 | Scikit Learn에서는 분류 알고리즘을 구현한 클래스를 Classifier로, 그리고 회귀 알고리즘을 구현한 클래스를 Regressor로 지칭 | Classifier와 Regressor를 합쳐서 Estimator 클래스라고 부름. 즉, 지도학습의 모든 알고리즘을 구현한 클래스를 통칭해서 Estimator라고 부름 | . Scikit-Learn의 다양한 모듈은 교재 94p,95p 참고 . 머신러닝 모델을 구축하는 주요 프로세스 = feature의 가공, 변경, 추출을 수행하는 feature processing, ML 알고리즙 학습/예측 수행, 그리고 모델 평가 단계를 반복적으로 수행하는 것 | . 사이킷런에 내장되어 있는 데이터 세트는 일반적으로 dict형태 | 이때 key는 data(feature의 데이터 세트),target(레이블 값, 숫자 결과값 데이터 세트),target_names(개별 레이블의 이름), feature_names(feature의 이름), DESCR 데이터 세트에 대한 설명과 각 feature의 설명 . | 앞에 두 key는 ndarray, 다음 두개는 ndarray 또는 list 그 다음은 str/ . | .",
            "url": "https://rhkrehtjd.github.io/INTROml/2021/12/31/intro.html",
            "relUrl": "/2021/12/31/intro.html",
            "date": " • Dec 31, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Machine Learning?",
            "content": "&#45936;&#51060;&#53552;&#50640; &#47784;&#45944;&#51012; &#47582;&#52632;&#45796; . 애플리케이션을 수정하지 않고도 데이터를 기반으로 패턴을 학습하고 결과를 예측하는 알고리즘 기법을 통칭 | . 데이터 기반으로 통계적인 신뢰도를 강화하고 예측 오류를 최소화하기 위한 다양한 수학적 기법을 적용해 데이터 내의 패턴을 스스로 인지하고 신뢰도 있는 예측 결과를 도출 | . 데이터를 관통하는 패턴을 학습, 이에 기반한 예측 수행 | . 모델을 맞춘다? 모델을 학습시키는 기법들에는 딥러닝, 나이브베이즈, 디시전트리 등이 있음, 모델을 맞추는 행위를 하지 않으면 이 모델은 어떤 문제도 해결할 수가 없음, 따라서 데이터를 모델에 맞추는 행위가 필요함 | . 따라서 이 데이터에 문제를 최대한 많이 맞출 수 있도록 모델을 최적화하여야 하는데 이렇게 최적화가 된 모델이 그 데이터에 해당된 문제를 해결할 수 있게 됨 | . 분류 :지도 학습(Supervised Learning), 비지도 학습(Un-supervised Learning), 강화 학습(Reinforcement Learning) 지도학습 $ to$ 분류(Classification)와 회귀(Regression)로 나눌 수 있음 . . data? Garbage In $ to$ Garbage Out : data도 질이 중요하다 | . 데이터를 이해하고 효율적으로 가공,처리,추출하여 최적의 데이터를 기반으로 알고리즘을 구동할 수 있도록 준비하는 능력 필요 | . . 만약 온도, 습도, 풍속을 정리해놓은 데이터가 있을 때 눈이 오는 여부를 다양한 기법으로 해결할 수 있음 . 1) 조건을 정해서 해결한다.(decision tree 등) . 2) 수식(가중치)으로 해결한다.(선형 회귀, 딥러닝 등) . 이러한 접근 방식을 통해서 가지고 있는 데이터를 50%정도만 해결했다면 이 접근 방식들은 썩 좋지 않은 방식일 것임 . 따라서 머신러닝을 학습한다는 것은 이 정답을 최대한 맞출 수 있도록 모델을 최대한 최적화한다는 의미임. 이렇게 가장 좋은 성능이 나올 수 있는 식과 조건을 찾아나가는 것을 기계가 스스로 하는 것을 머신러닝이라고 생각할 수도 있겠음. . . 딥러닝 등 머신러닝 기법들 전반적으로 공부할 필요가 있다 . 딥러닝 : 자연어와 이미지 처리에 강하다. 그렇지만 다른 과업처리에 있어서도 항상 우수한 결과를 도출해내는 것은 아니다. 대표적으로 KAGGLE에 있는 TITANIC자료에서 실제로 산 승객과 죽은 승객을 처리해내는 과업을 수행할 땐 딥러닝보다 머신러닝의 모델이 더 좋은 결과를 도출해냈음 | . &#44208;&#44397; &#47785;&#51201;&#51008; &#45936;&#51060;&#53552;&#47484; &#47784;&#45944;&#50640; &#52572;&#51201;&#54868; &#49884;&#53412;&#45716; &#44163;&#51060;&#45796; . 머신러닝 논문에 머신러닝 기법들간에 성능을 비교한 표도 있음. 즉, 머신러닝 기법들은 다양한 기법들이 있기 때문에 그 것들간의 차이점과, 각각의 알고리즘이 무엇을 최적화하려는 것인지의 관점에서 이해해보아야함 . . . &#54028;&#51060;&#50028; &#47672;&#49888;&#47084;&#45789; &#49373;&#53468;&#44228;&#47484; &#44396;&#49457;&#54616;&#45716; &#51452;&#50836; &#54056;&#53412;&#51648; . 머신러닝 패키지 : Scikit-Learn . | 행렬/ 선형대수/ 통계 패키지 : Numpy, SciPy . | 데이터 핸들링 : Pandas(Numpy는 행렬 기반의 데이터 처리에 특화) $ to$ 2차원 데이터 처리에 특화,Matplotlib . | 시각화 : matplotlib(너무 세분화 되어 있어서 익히기 어려움, 시각적인 면에서도 투박),Seaborn(matplotlib의 대안이 될 것) . | .",
            "url": "https://rhkrehtjd.github.io/INTROml/2021/12/28/intro.html",
            "relUrl": "/2021/12/28/intro.html",
            "date": " • Dec 28, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://rhkrehtjd.github.io/INTROml/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://rhkrehtjd.github.io/INTROml/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}