<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.7.1 -->
<title>2022/01/22/SAT | INTROml</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="2022/01/22/SAT" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="An easy to use blogging platform with support for Jupyter Notebooks." />
<meta property="og:description" content="An easy to use blogging platform with support for Jupyter Notebooks." />
<link rel="canonical" href="https://rhkrehtjd.github.io/INTROml/2022/01/22/intro.html" />
<meta property="og:url" content="https://rhkrehtjd.github.io/INTROml/2022/01/22/intro.html" />
<meta property="og:site_name" content="INTROml" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-01-22T00:00:00-06:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="2022/01/22/SAT" />
<script type="application/ld+json">
{"url":"https://rhkrehtjd.github.io/INTROml/2022/01/22/intro.html","@type":"BlogPosting","headline":"2022/01/22/SAT","dateModified":"2022-01-22T00:00:00-06:00","datePublished":"2022-01-22T00:00:00-06:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://rhkrehtjd.github.io/INTROml/2022/01/22/intro.html"},"description":"An easy to use blogging platform with support for Jupyter Notebooks.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/INTROml/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://rhkrehtjd.github.io/INTROml/feed.xml" title="INTROml" /><link rel="shortcut icon" type="image/x-icon" href="/INTROml/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/INTROml/">INTROml</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/INTROml/about/">About Me</a><a class="page-link" href="/INTROml/search/">Search</a><a class="page-link" href="/INTROml/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">2022/01/22/SAT</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-01-22T00:00:00-06:00" itemprop="datePublished">
        Jan 22, 2022
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      15 min read
    
</span></p>

    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/rhkrehtjd/INTROml/tree/master/_notebooks/2022-01-22-intro.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/INTROml/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/rhkrehtjd/INTROml/master?filepath=_notebooks%2F2022-01-22-intro.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/INTROml/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/rhkrehtjd/INTROml/blob/master/_notebooks/2022-01-22-intro.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/INTROml/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
          <div class="px-2">
  <a href="https://deepnote.com/launch?url=https%3A%2F%2Fgithub.com%2Frhkrehtjd%2FINTROml%2Fblob%2Fmaster%2F_notebooks%2F2022-01-22-intro.ipynb" target="_blank">
      <img class="notebook-badge-image" src="/INTROml/assets/badges/deepnote.svg" alt="Launch in Deepnote"/>
  </a>
</div>

        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-01-22-intro.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote><h3 id="&#53664;&#54589;-&#47784;&#45944;&#47553;"><strong><em>&#53664;&#54589; &#47784;&#45944;&#47553;</em></strong><a class="anchor-link" href="#&#53664;&#54589;-&#47784;&#45944;&#47553;"> </a></h3><p>문서 집합에 숨어 있는 주제를 찾아내는 것. 토픽 모델링을 적용해 숨어 있는 중요 주제를 효과적으로 찾아낼 수 있다. 중심 단어를 함축적으로 추출. 머신러닝 기반의 토픽 모델링에 자주 사용되는 기법은 LSA와 LDA이다. LDA는 Count 기반의 벡터화만 사용한다.</p>
</blockquote>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_20newsgroups</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">LatentDirichletAllocation</span>

<span class="c1"># 모토사이클, 야구, 그래픽스, 윈도우즈, 중동, 기독교, 전자공학, 의학 등 8개 주제를 추출. </span>
<span class="n">cats</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;rec.motorcycles&#39;</span><span class="p">,</span> <span class="s1">&#39;rec.sport.baseball&#39;</span><span class="p">,</span> <span class="s1">&#39;comp.graphics&#39;</span><span class="p">,</span> <span class="s1">&#39;comp.windows.x&#39;</span><span class="p">,</span>
        <span class="s1">&#39;talk.politics.mideast&#39;</span><span class="p">,</span> <span class="s1">&#39;soc.religion.christian&#39;</span><span class="p">,</span> <span class="s1">&#39;sci.electronics&#39;</span><span class="p">,</span> <span class="s1">&#39;sci.med&#39;</span>  <span class="p">]</span>

<span class="c1"># categories 파라미터를 통해 필요한 주제만 필터링해 추출하고 추출된 텍스트를 Count 기반으로 벡터화 변환</span>
<span class="c1"># 위에서 cats 변수로 기재된 category만 추출. featch_20newsgroups( )의 categories에 cats 입력</span>
<span class="n">news_df</span><span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">,</span><span class="n">remove</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;headers&#39;</span><span class="p">,</span> <span class="s1">&#39;footers&#39;</span><span class="p">,</span> <span class="s1">&#39;quotes&#39;</span><span class="p">),</span> 
                            <span class="n">categories</span><span class="o">=</span><span class="n">cats</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1">#LDA 는 Count기반의 Vectorizer만 적용합니다.  </span>
<span class="n">count_vect</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">max_df</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">min_df</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stop_words</span><span class="o">=</span><span class="s1">&#39;english&#39;</span><span class="p">,</span> <span class="n">ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="n">feat_vect</span> <span class="o">=</span> <span class="n">count_vect</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">news_df</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;CountVectorizer Shape:&#39;</span><span class="p">,</span> <span class="n">feat_vect</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CountVectorizer Shape: (7862, 1000)
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>이렇게 feature 벡터화된 데이터 세트를 기반으로 LDA 토픽 모델링을 수행</li>
<li>토픽의 개수는 위의 뉴스그룹에서 추출한 주제와 동일한 8개로 정한다. </li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lda</span> <span class="o">=</span> <span class="n">LatentDirichletAllocation</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">lda</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">feat_vect</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>LatentDirichletAllocation(n_components=8, random_state=0)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>위 객체는 components_ 속성값을 가지게 된다. 이 속성값은 개별 토픽별로 각 word feature가 얼마나 많이 그 토픽에 할당됐는지에 대한 수치를 가지고 있다. 높은 값일수록 해당 word feature는 그 토픽의 중심 word가 된다.</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">lda</span><span class="o">.</span><span class="n">components_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">lda</span><span class="o">.</span><span class="n">components_</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(8, 1000)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([[3.60992018e+01, 1.35626798e+02, 2.15751867e+01, ...,
        3.02911688e+01, 8.66830093e+01, 6.79285199e+01],
       [1.25199920e-01, 1.44401815e+01, 1.25045596e-01, ...,
        1.81506995e+02, 1.25097844e-01, 9.39593286e+01],
       [3.34762663e+02, 1.25176265e-01, 1.46743299e+02, ...,
        1.25105772e-01, 3.63689741e+01, 1.25025218e-01],
       ...,
       [3.60204965e+01, 2.08640688e+01, 4.29606813e+00, ...,
        1.45056650e+01, 8.33854413e+00, 1.55690009e+01],
       [1.25128711e-01, 1.25247756e-01, 1.25005143e-01, ...,
        9.17278769e+01, 1.25177668e-01, 3.74575887e+01],
       [5.49258690e+01, 4.47009532e+00, 9.88524814e+00, ...,
        4.87048440e+01, 1.25034678e-01, 1.25074632e-01]])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>8개의 토픽별로 1000개의 word feature가 해당 토픽별로 연관도 값을 가지고 있다. </li>
<li>display_topics() 함수를 만들어서 각 토픽별로 연관도가 높은 순으로 Word를 나열해보자.</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">display_topic_words</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">,</span> <span class="n">no_top_words</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">topic_index</span><span class="p">,</span> <span class="n">topic</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">components_</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Topic #&#39;</span><span class="p">,</span><span class="n">topic_index</span><span class="p">)</span>

        <span class="c1"># components_ array에서 가장 값이 큰 순으로 정렬했을 때, 그 값의 array index를 반환. </span>
        <span class="n">topic_word_indexes</span> <span class="o">=</span> <span class="n">topic</span><span class="o">.</span><span class="n">argsort</span><span class="p">()[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">top_indexes</span><span class="o">=</span><span class="n">topic_word_indexes</span><span class="p">[:</span><span class="n">no_top_words</span><span class="p">]</span>
        
        <span class="c1"># top_indexes대상인 index별로 feature_names에 해당하는 word feature 추출 후 join으로 concat</span>
        <span class="n">feature_concat</span> <span class="o">=</span> <span class="s1">&#39; + &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">feature_names</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">+</span><span class="s1">&#39;*&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">topic</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">top_indexes</span><span class="p">])</span>                
        <span class="nb">print</span><span class="p">(</span><span class="n">feature_concat</span><span class="p">)</span>

<span class="c1"># CountVectorizer객체내의 전체 word들의 명칭을 get_features_names( )를 통해 추출</span>
<span class="n">feature_names</span> <span class="o">=</span> <span class="n">count_vect</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>

<span class="c1"># Topic별 가장 연관도가 높은 word를 15개만 추출</span>
<span class="n">display_topic_words</span><span class="p">(</span><span class="n">lda</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>

<span class="c1"># 모토사이클, 야구, 그래픽스, 윈도우즈, 중동, 기독교, 전자공학, 의학 등 8개 주제를 추출. </span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
Topic # 0
year*703.2 + 10*563.6 + game*476.3 + medical*413.2 + health*377.4 + team*346.8 + 12*343.9 + 20*340.9 + disease*332.1 + cancer*319.9 + 1993*318.3 + games*317.0 + years*306.5 + patients*299.8 + good*286.3

Topic # 1
don*1454.3 + just*1392.8 + like*1190.8 + know*1178.1 + people*836.9 + said*802.5 + think*799.7 + time*754.2 + ve*676.3 + didn*675.9 + right*636.3 + going*625.4 + say*620.7 + ll*583.9 + way*570.3

Topic # 2
image*1047.7 + file*999.1 + jpeg*799.1 + program*495.6 + gif*466.0 + images*443.7 + output*442.3 + format*442.3 + files*438.5 + color*406.3 + entry*387.6 + 00*334.8 + use*308.5 + bit*308.4 + 03*258.7

Topic # 3
like*620.7 + know*591.7 + don*543.7 + think*528.4 + use*514.3 + does*510.2 + just*509.1 + good*425.8 + time*417.4 + book*410.7 + read*402.9 + information*395.2 + people*393.5 + used*388.2 + post*368.4

Topic # 4
armenian*960.6 + israel*815.9 + armenians*699.7 + jews*690.9 + turkish*686.1 + people*653.0 + israeli*476.1 + jewish*467.0 + government*464.4 + war*417.8 + dos dos*401.1 + turkey*393.5 + arab*386.1 + armenia*346.3 + 000*345.2

Topic # 5
edu*1613.5 + com*841.4 + available*761.5 + graphics*708.0 + ftp*668.1 + data*517.9 + pub*508.2 + motif*460.4 + mail*453.3 + widget*447.4 + software*427.6 + mit*421.5 + information*417.3 + version*413.7 + sun*402.4

Topic # 6
god*2013.0 + people*721.0 + jesus*688.7 + church*663.0 + believe*563.0 + christ*553.1 + does*500.1 + christian*474.8 + say*468.6 + think*446.0 + christians*443.5 + bible*422.9 + faith*420.1 + sin*396.5 + life*371.2

Topic # 7
use*685.8 + dos*635.0 + thanks*596.0 + windows*548.7 + using*486.5 + window*483.1 + does*456.2 + display*389.1 + help*385.2 + like*382.8 + problem*375.7 + server*370.2 + need*366.3 + know*355.5 + run*315.3
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>문서 군집화 소개와 실습</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>비슷한 텍스트 구성의 문서를 군집화 하는 것. 동일한 군집에 속하는 문서를 같은 카테고리 소속으로 분류할 수 있으므로 앞에서 소개한 텍스트 분류 기반의 문서 분류와 유사하다. 하지만 텍스트 분류 기반의 문서 분류는 사전에 결정 카테고리 값을 가진 학습 데이터 세트가 필요한 데 반해, 문섭 군집화는 학습 데이터 세트가 필요없는 비지도학습 기반으로 동작한다. 이전 장에서 배웠던 군집화 기법을 활용해 텍스트 기반의 문서 군집화를 적용한다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Opinion Review 데이터 세트를 이용한 문서 군집화 수행하기
<pre><code>해당 데이터 세트는 51개의 텍스트 파일로 구성돼 있으며 각 파일은 100개 정도의 문장을 가지고 있다. </code></pre>
</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">glob</span> <span class="o">,</span><span class="nn">os</span>

<span class="n">path</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">&#39;C:\Users\ehfus\Downloads\OpinosisDataset1.0\OpinosisDataset1.0\topics&#39;</span>                     
<span class="c1"># path로 지정한 디렉토리 밑에 있는 모든 .data 파일들의 파일명을 리스트로 취합</span>
<span class="n">all_files</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;*.data&quot;</span><span class="p">))</span>    
<span class="n">filename_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">opinion_text</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># 개별 파일들의 파일명은 filename_list 리스트로 취합, </span>
<span class="c1"># 개별 파일들의 파일내용은 DataFrame로딩 후 다시 string으로 변환하여 opinion_text 리스트로 취합 </span>
<span class="k">for</span> <span class="n">file_</span> <span class="ow">in</span> <span class="n">all_files</span><span class="p">:</span>
    <span class="c1"># 개별 파일을 읽어서 DataFrame으로 생성 </span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="n">file_</span><span class="p">,</span><span class="n">index_col</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;latin1&#39;</span><span class="p">)</span>
    
    <span class="c1"># 절대경로로 주어진 file 명을 가공. 만일 Linux에서 수행시에는 아래 \\를 / 변경. 맨 마지막 .data 확장자도 제거</span>
    <span class="n">filename_</span> <span class="o">=</span> <span class="n">file_</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\\</span><span class="s1">&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">filename</span> <span class="o">=</span> <span class="n">filename_</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1">#파일명 리스트와 파일내용 리스트에 파일명과 파일 내용을 추가. </span>
    <span class="n">filename_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
    <span class="n">opinion_text</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">to_string</span><span class="p">())</span>

<span class="c1"># 파일명 리스트와 파일내용 리스트를  DataFrame으로 생성</span>
<span class="n">document_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;filename&#39;</span><span class="p">:</span><span class="n">filename_list</span><span class="p">,</span> <span class="s1">&#39;opinion_text&#39;</span><span class="p">:</span><span class="n">opinion_text</span><span class="p">})</span>
<span class="n">document_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>filename</th>
      <th>opinion_text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>accuracy_garmin_nuvi_255W_gps</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>bathroom_bestwestern_hotel_sfo</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>battery-life_amazon_kindle</td>
      <td>...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>battery-life_ipod_nano_8gb</td>
      <td>...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>battery-life_netbook_1005ha</td>
      <td>...</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>각 파일 이름 자체만으로 의견의 텍스트가 어떠한 제품/서비스에 대한 리뷰인지 알 수 있다. </li>
<li>문서를 TF-IDF 형태로 feature 벡터화하겠다. </li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">nltk.stem</span> <span class="kn">import</span> <span class="n">WordNetLemmatizer</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">string</span>

<span class="c1"># nltk는 </span>
<span class="n">remove_punct_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="nb">ord</span><span class="p">(</span><span class="n">punct</span><span class="p">),</span> <span class="kc">None</span><span class="p">)</span> <span class="k">for</span> <span class="n">punct</span> <span class="ow">in</span> <span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">)</span>
<span class="n">lemmar</span> <span class="o">=</span> <span class="n">WordNetLemmatizer</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">LemTokens</span><span class="p">(</span><span class="n">tokens</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">lemmar</span><span class="o">.</span><span class="n">lemmatize</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">LemNormalize</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">LemTokens</span><span class="p">(</span><span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">translate</span><span class="p">(</span><span class="n">remove_punct_dict</span><span class="p">)))</span>


<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>

<span class="n">tfidf_vect</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">LemNormalize</span><span class="p">,</span> <span class="n">stop_words</span><span class="o">=</span><span class="s1">&#39;english&#39;</span> <span class="p">,</span> \
                             <span class="n">ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">min_df</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">max_df</span><span class="o">=</span><span class="mf">0.85</span> <span class="p">)</span>

<span class="c1">#opinion_text 컬럼값으로 feature vectorization 수행</span>
<span class="n">feature_vect</span> <span class="o">=</span> <span class="n">tfidf_vect</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">document_df</span><span class="p">[</span><span class="s1">&#39;opinion_text&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>문서별 텍스트가 TF-IDF 변환된 feature 벡터화 행렬 데이터에 대해서 군집화를 수행해 어떤 문서끼리 군집되는지 확인해보자. 군집화 기법은 K-평균을 적용한다. </li>
<li>먼저 5개의 중심(Centroid) 기반으로 어떻게 군집화되는지 확인해 보자. </li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>

<span class="c1"># 5개 집합으로 군집화 수행. 예제를 위해 동일한 클러스터링 결과 도출용 random_state=0 </span>
<span class="n">km_cluster</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">km_cluster</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">feature_vect</span><span class="p">)</span>
<span class="n">cluster_label</span> <span class="o">=</span> <span class="n">km_cluster</span><span class="o">.</span><span class="n">labels_</span>
<span class="n">cluster_centers</span> <span class="o">=</span> <span class="n">km_cluster</span><span class="o">.</span><span class="n">cluster_centers_</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>각 데이터별로 할당된 군집의 레이블을 파일명과 파일 내용을 가지고 있는 document_df DataFrame에 'cluster_label' 칼럼을 추가해 저장한다. </li>
<li>각 파일명은 의견 리뷰에 대한 주제를 나타낸다.</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">document_df</span><span class="p">[</span><span class="s1">&#39;cluster_label&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cluster_label</span>
<span class="n">document_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>filename</th>
      <th>opinion_text</th>
      <th>cluster_label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>accuracy_garmin_nuvi_255W_gps</td>
      <td>...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>bathroom_bestwestern_hotel_sfo</td>
      <td>...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>battery-life_amazon_kindle</td>
      <td>...</td>
      <td>3</td>
    </tr>
    <tr>
      <th>3</th>
      <td>battery-life_ipod_nano_8gb</td>
      <td>...</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>battery-life_netbook_1005ha</td>
      <td>...</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>판다스 DataFrame의 sort_values(by=지정칼럼명)를 수행하면 인자로 입력된 '정렬칼럼명'으로 데이터를 정렬할 수 있다. </li>
<li>먼저 cluster_label=0인 데이터 세트를 살펴보자</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">document_df</span><span class="p">[</span><span class="n">document_df</span><span class="p">[</span><span class="s1">&#39;cluster_label&#39;</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;filename&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>filename</th>
      <th>opinion_text</th>
      <th>cluster_label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>accuracy_garmin_nuvi_255W_gps</td>
      <td>...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>directions_garmin_nuvi_255W_gps</td>
      <td>...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>9</th>
      <td>display_garmin_nuvi_255W_gps</td>
      <td>...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>33</th>
      <td>satellite_garmin_nuvi_255W_gps</td>
      <td>...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>34</th>
      <td>screen_garmin_nuvi_255W_gps</td>
      <td>...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>43</th>
      <td>speed_garmin_nuvi_255W_gps</td>
      <td>...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>47</th>
      <td>transmission_toyota_camry_2007</td>
      <td>...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>48</th>
      <td>updates_garmin_nuvi_255W_gps</td>
      <td>...</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">document_df</span><span class="p">[</span><span class="n">document_df</span><span class="p">[</span><span class="s1">&#39;cluster_label&#39;</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;filename&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>filename</th>
      <th>opinion_text</th>
      <th>cluster_label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>bathroom_bestwestern_hotel_sfo</td>
      <td>...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>13</th>
      <td>food_holiday_inn_london</td>
      <td>...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>14</th>
      <td>food_swissotel_chicago</td>
      <td>...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>15</th>
      <td>free_bestwestern_hotel_sfo</td>
      <td>...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>20</th>
      <td>location_bestwestern_hotel_sfo</td>
      <td>...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>21</th>
      <td>location_holiday_inn_london</td>
      <td>...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>24</th>
      <td>parking_bestwestern_hotel_sfo</td>
      <td>...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>28</th>
      <td>price_holiday_inn_london</td>
      <td>...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>32</th>
      <td>room_holiday_inn_london</td>
      <td>...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>30</th>
      <td>rooms_bestwestern_hotel_sfo</td>
      <td>...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>31</th>
      <td>rooms_swissotel_chicago</td>
      <td>...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>38</th>
      <td>service_bestwestern_hotel_sfo</td>
      <td>...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>39</th>
      <td>service_holiday_inn_london</td>
      <td>...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>40</th>
      <td>service_swissotel_hotel_chicago</td>
      <td>...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>45</th>
      <td>staff_bestwestern_hotel_sfo</td>
      <td>...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>46</th>
      <td>staff_swissotel_chicago</td>
      <td>...</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>전반적으로 군집화된 결과를 살펴보면 군집 개수가 약간 많게 설정돼 있어서 세분화되어 군집화된 경향이 있다. 중심 개수를 5개에서 3개로 낮춰서 3개 그룹으로 군집화한 뒤 결과를 확인해 보자</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>

<span class="c1"># 3개의 집합으로 군집화 </span>
<span class="n">km_cluster</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">km_cluster</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">feature_vect</span><span class="p">)</span>
<span class="n">cluster_label</span> <span class="o">=</span> <span class="n">km_cluster</span><span class="o">.</span><span class="n">labels_</span>


<span class="c1"># 소속 클러스터를 cluster_label 컬럼으로 할당하고 cluster_label 값으로 정렬</span>
<span class="n">document_df</span><span class="p">[</span><span class="s1">&#39;cluster_label&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cluster_label</span>
<span class="n">document_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;cluster_label&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>filename</th>
      <th>opinion_text</th>
      <th>cluster_label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>accuracy_garmin_nuvi_255W_gps</td>
      <td>...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>48</th>
      <td>updates_garmin_nuvi_255W_gps</td>
      <td>...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>44</th>
      <td>speed_windows7</td>
      <td>...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>43</th>
      <td>speed_garmin_nuvi_255W_gps</td>
      <td>...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>42</th>
      <td>sound_ipod_nano_8gb</td>
      <td>headphone jack i got a clear case for it a...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>41</th>
      <td>size_asus_netbook_1005ha</td>
      <td>...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>36</th>
      <td>screen_netbook_1005ha</td>
      <td>...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>35</th>
      <td>screen_ipod_nano_8gb</td>
      <td>...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>34</th>
      <td>screen_garmin_nuvi_255W_gps</td>
      <td>...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>33</th>
      <td>satellite_garmin_nuvi_255W_gps</td>
      <td>...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>27</th>
      <td>price_amazon_kindle</td>
      <td>...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>26</th>
      <td>performance_netbook_1005ha</td>
      <td>...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>49</th>
      <td>video_ipod_nano_8gb</td>
      <td>...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>23</th>
      <td>navigation_amazon_kindle</td>
      <td>...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>19</th>
      <td>keyboard_netbook_1005ha</td>
      <td>...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>50</th>
      <td>voice_garmin_nuvi_255W_gps</td>
      <td>...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>9</th>
      <td>display_garmin_nuvi_255W_gps</td>
      <td>...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>battery-life_netbook_1005ha</td>
      <td>...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>battery-life_ipod_nano_8gb</td>
      <td>...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>battery-life_amazon_kindle</td>
      <td>...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>directions_garmin_nuvi_255W_gps</td>
      <td>...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>10</th>
      <td>eyesight-issues_amazon_kindle</td>
      <td>...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>11</th>
      <td>features_windows7</td>
      <td>...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>12</th>
      <td>fonts_amazon_kindle</td>
      <td>...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>buttons_amazon_kindle</td>
      <td>...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>13</th>
      <td>food_holiday_inn_london</td>
      <td>...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>39</th>
      <td>service_holiday_inn_london</td>
      <td>...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>38</th>
      <td>service_bestwestern_hotel_sfo</td>
      <td>...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>bathroom_bestwestern_hotel_sfo</td>
      <td>...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>14</th>
      <td>food_swissotel_chicago</td>
      <td>...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>20</th>
      <td>location_bestwestern_hotel_sfo</td>
      <td>...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>24</th>
      <td>parking_bestwestern_hotel_sfo</td>
      <td>...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>15</th>
      <td>free_bestwestern_hotel_sfo</td>
      <td>...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>31</th>
      <td>rooms_swissotel_chicago</td>
      <td>...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>30</th>
      <td>rooms_bestwestern_hotel_sfo</td>
      <td>...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>45</th>
      <td>staff_bestwestern_hotel_sfo</td>
      <td>...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>40</th>
      <td>service_swissotel_hotel_chicago</td>
      <td>...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>21</th>
      <td>location_holiday_inn_london</td>
      <td>...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>46</th>
      <td>staff_swissotel_chicago</td>
      <td>...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>32</th>
      <td>room_holiday_inn_london</td>
      <td>...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>28</th>
      <td>price_holiday_inn_london</td>
      <td>...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>47</th>
      <td>transmission_toyota_camry_2007</td>
      <td>...</td>
      <td>2</td>
    </tr>
    <tr>
      <th>16</th>
      <td>gas_mileage_toyota_camry_2007</td>
      <td>...</td>
      <td>2</td>
    </tr>
    <tr>
      <th>6</th>
      <td>comfort_honda_accord_2008</td>
      <td>...</td>
      <td>2</td>
    </tr>
    <tr>
      <th>7</th>
      <td>comfort_toyota_camry_2007</td>
      <td>...</td>
      <td>2</td>
    </tr>
    <tr>
      <th>29</th>
      <td>quality_toyota_camry_2007</td>
      <td>...</td>
      <td>2</td>
    </tr>
    <tr>
      <th>22</th>
      <td>mileage_honda_accord_2008</td>
      <td>...</td>
      <td>2</td>
    </tr>
    <tr>
      <th>18</th>
      <td>interior_toyota_camry_2007</td>
      <td>...</td>
      <td>2</td>
    </tr>
    <tr>
      <th>17</th>
      <td>interior_honda_accord_2008</td>
      <td>...</td>
      <td>2</td>
    </tr>
    <tr>
      <th>37</th>
      <td>seats_honda_accord_2008</td>
      <td>...</td>
      <td>2</td>
    </tr>
    <tr>
      <th>25</th>
      <td>performance_honda_accord_2008</td>
      <td>...</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Cluster별로 잘 구성됐음을 확인할 수 있다.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote><p>군집별 핵심 단어 추출해보자</p>
</blockquote>

<pre><code>  각 군집에 속한 문서는 핵심 단어를 주축으로 군집화돼 있을 것이다. 이번에는 각 군집을 구성하는 핵심 단어가 어떤 것이 있는지 확인해보자. KMeans 객체는 각 군집을 구성하는 단어 feature 가 군집의 중심을 기준으로 얼마나 가깝게 위치해 있는지 cluster_centers_라는 속성으로 제공한다. </code></pre>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cluster_centers</span> <span class="o">=</span> <span class="n">km_cluster</span><span class="o">.</span><span class="n">cluster_centers_</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;cluster_centers shape :&#39;</span><span class="p">,</span><span class="n">cluster_centers</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cluster_centers</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>cluster_centers shape : (3, 4611)
[[0.01005322 0.         0.         ... 0.00706287 0.         0.        ]
 [0.         0.00099499 0.00174637 ... 0.         0.00183397 0.00144581]
 [0.         0.00092551 0.         ... 0.         0.         0.        ]]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>cluster_centers_는 (3,2409) 배열이다. 이는 군집이 3개, word 피처가 2409개로 구성되었음을 의미한다. </li>
<li>각 행의 배열 값은 각 군집 내의 2409개 피처의 위치가 개별 중심과 얼마나 가까운가를 상대 값으로 나타낸 것이다. 0~1로 표현하며 1에 가까울수록 중심과 가까운 값을 의미한다. </li>
<li>이제 cluster<em>centers</em> 속성값을 이용해 각 군집별 핵심 단어를 찾아보자.</li>
<li>ndarray의 argsort()[:,::-1]를 이용하면 cluster_centers 배열 내 값이 큰 순으로 정렬된 위치 인덱스 값을 반환한다. </li>
<li>이 위치 인덱스 값을 통해 핵심 단어 피처의 이름을 출력한다. </li>
<li>이를 새로운 함수를 만들어 처리해보자</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_cluster_details</span><span class="p">(</span><span class="n">cluster_model</span><span class="p">,</span> <span class="n">cluster_data</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">,</span> <span class="n">clusters_num</span><span class="p">,</span> <span class="n">top_n_features</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">cluster_details</span> <span class="o">=</span> <span class="p">{}</span>
    
    <span class="c1"># cluster_centers array 의 값이 큰 순으로 정렬된 index 값을 반환</span>
    <span class="c1"># 군집 중심점(centroid)별 할당된 word 피처들의 거리값이 큰 순으로 값을 구하기 위함.  </span>
    <span class="n">centroid_feature_ordered_ind</span> <span class="o">=</span> <span class="n">cluster_model</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="o">.</span><span class="n">argsort</span><span class="p">()[:,::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="c1">#개별 군집별로 iteration하면서 핵심단어, 그 단어의 중심 위치 상대값, 대상 파일명 입력</span>
    <span class="k">for</span> <span class="n">cluster_num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">clusters_num</span><span class="p">):</span>
        <span class="c1"># 개별 군집별 정보를 담을 데이터 초기화. </span>
        <span class="n">cluster_details</span><span class="p">[</span><span class="n">cluster_num</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">cluster_details</span><span class="p">[</span><span class="n">cluster_num</span><span class="p">][</span><span class="s1">&#39;cluster&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cluster_num</span>
        
        <span class="c1"># cluster_centers_.argsort()[:,::-1] 로 구한 index 를 이용하여 top n 피처 단어를 구함. </span>
        <span class="n">top_feature_indexes</span> <span class="o">=</span> <span class="n">centroid_feature_ordered_ind</span><span class="p">[</span><span class="n">cluster_num</span><span class="p">,</span> <span class="p">:</span><span class="n">top_n_features</span><span class="p">]</span>
        <span class="n">top_features</span> <span class="o">=</span> <span class="p">[</span> <span class="n">feature_names</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="n">top_feature_indexes</span> <span class="p">]</span>
        
        <span class="c1"># top_feature_indexes를 이용해 해당 피처 단어의 중심 위치 상댓값 구함 </span>
        <span class="n">top_feature_values</span> <span class="o">=</span> <span class="n">cluster_model</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[</span><span class="n">cluster_num</span><span class="p">,</span> <span class="n">top_feature_indexes</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        
        <span class="c1"># cluster_details 딕셔너리 객체에 개별 군집별 핵심 단어와 중심위치 상대값, 그리고 해당 파일명 입력</span>
        <span class="n">cluster_details</span><span class="p">[</span><span class="n">cluster_num</span><span class="p">][</span><span class="s1">&#39;top_features&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">top_features</span>
        <span class="n">cluster_details</span><span class="p">[</span><span class="n">cluster_num</span><span class="p">][</span><span class="s1">&#39;top_features_value&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">top_feature_values</span>
        <span class="n">filenames</span> <span class="o">=</span> <span class="n">cluster_data</span><span class="p">[</span><span class="n">cluster_data</span><span class="p">[</span><span class="s1">&#39;cluster_label&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">cluster_num</span><span class="p">][</span><span class="s1">&#39;filename&#39;</span><span class="p">]</span>
        <span class="n">filenames</span> <span class="o">=</span> <span class="n">filenames</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">cluster_details</span><span class="p">[</span><span class="n">cluster_num</span><span class="p">][</span><span class="s1">&#39;filenames&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">filenames</span>
        
    <span class="k">return</span> <span class="n">cluster_details</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>get_cluster_details()를 호출하면 dictionary를 원소로 가지는 리스트인 cluster_details를 반환한다. 이 리스트에는 개별 군집번호, 핵심 단어, 핵심단어 중심 위치 상댓값, 파일명 속성 값 정보등이 있는데 이를 좀 더 보기 좋게 표현하기 위해서 별도의 함수를 만들자</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">print_cluster_details</span><span class="p">(</span><span class="n">cluster_details</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">cluster_num</span><span class="p">,</span> <span class="n">cluster_detail</span> <span class="ow">in</span> <span class="n">cluster_details</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;####### Cluster </span><span class="si">{0}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cluster_num</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Top features:&#39;</span><span class="p">,</span> <span class="n">cluster_detail</span><span class="p">[</span><span class="s1">&#39;top_features&#39;</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Reviews 파일명 :&#39;</span><span class="p">,</span><span class="n">cluster_detail</span><span class="p">[</span><span class="s1">&#39;filenames&#39;</span><span class="p">][:</span><span class="mi">7</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;==================================================&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">feature_names</span> <span class="o">=</span> <span class="n">tfidf_vect</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>

<span class="n">cluster_details</span> <span class="o">=</span> <span class="n">get_cluster_details</span><span class="p">(</span><span class="n">cluster_model</span><span class="o">=</span><span class="n">km_cluster</span><span class="p">,</span> <span class="n">cluster_data</span><span class="o">=</span><span class="n">document_df</span><span class="p">,</span>\
                                  <span class="n">feature_names</span><span class="o">=</span><span class="n">feature_names</span><span class="p">,</span> <span class="n">clusters_num</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">top_n_features</span><span class="o">=</span><span class="mi">10</span> <span class="p">)</span>
<span class="n">print_cluster_details</span><span class="p">(</span><span class="n">cluster_details</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>####### Cluster 0
Top features: [&#39;screen&#39;, &#39;battery&#39;, &#39;keyboard&#39;, &#39;battery life&#39;, &#39;life&#39;, &#39;kindle&#39;, &#39;direction&#39;, &#39;video&#39;, &#39;size&#39;, &#39;voice&#39;]
Reviews 파일명 : [&#39;accuracy_garmin_nuvi_255W_gps&#39;, &#39;battery-life_amazon_kindle&#39;, &#39;battery-life_ipod_nano_8gb&#39;, &#39;battery-life_netbook_1005ha&#39;, &#39;buttons_amazon_kindle&#39;, &#39;directions_garmin_nuvi_255W_gps&#39;, &#39;display_garmin_nuvi_255W_gps&#39;]
==================================================
####### Cluster 1
Top features: [&#39;room&#39;, &#39;hotel&#39;, &#39;service&#39;, &#39;staff&#39;, &#39;food&#39;, &#39;location&#39;, &#39;bathroom&#39;, &#39;clean&#39;, &#39;price&#39;, &#39;parking&#39;]
Reviews 파일명 : [&#39;bathroom_bestwestern_hotel_sfo&#39;, &#39;food_holiday_inn_london&#39;, &#39;food_swissotel_chicago&#39;, &#39;free_bestwestern_hotel_sfo&#39;, &#39;location_bestwestern_hotel_sfo&#39;, &#39;location_holiday_inn_london&#39;, &#39;parking_bestwestern_hotel_sfo&#39;]
==================================================
####### Cluster 2
Top features: [&#39;interior&#39;, &#39;seat&#39;, &#39;mileage&#39;, &#39;comfortable&#39;, &#39;gas&#39;, &#39;gas mileage&#39;, &#39;transmission&#39;, &#39;car&#39;, &#39;performance&#39;, &#39;quality&#39;]
Reviews 파일명 : [&#39;comfort_honda_accord_2008&#39;, &#39;comfort_toyota_camry_2007&#39;, &#39;gas_mileage_toyota_camry_2007&#39;, &#39;interior_honda_accord_2008&#39;, &#39;interior_toyota_camry_2007&#39;, &#39;mileage_honda_accord_2008&#39;, &#39;performance_honda_accord_2008&#39;]
==================================================
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote><h3 id="&#47928;&#49436;-&#50976;&#49324;&#46020;">&#47928;&#49436; &#50976;&#49324;&#46020;<a class="anchor-link" href="#&#47928;&#49436;-&#50976;&#49324;&#46020;"> </a></h3><p>中 코사인 유사도를 알아보자. 문서와 문서 간의 유사도 비교는 일반적으로 코사인 유사도를 사용한다. 코사인 유사도는 벡터와 벡터 간의 유사도를 비교할 때 벡터의 크기보다는 벡터의 상호 방향성이 얼마나 유사한지에 기반한다. 즉, 코사인 유사도는 두 벡터 사이의 사잇각을 구해서 얼마나 유사한지 수치로 적용한 것이다.</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>두 벡터의 사잇각은 유사하거나 관련이 없거나 아예 반대 관계가 될 수 있다.</li>
<li>두 벡터 A와 B의 코사인 값은 다음 식으로 구할 수 있다. </li>
<li>$A * B = |A||B|cos\theta$</li>
<li>따라서 유사도 $cos\theta$는 다음과 같이 두 벡터의 내적을 총 벡터 크기의 합으로 나눈 것이다. </li>
<li>$similarity = cos\theta = \frac{A*B}{|A||B|}$</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>코사인 유사도가 문서의 유사도 비교에 가장 많이 사용되는 이유가 있다. 문서를 피처 벡터화 변환하면 차원이 매우 많은 희소 행렬이 되기 쉽다. 이러한 희소 행렬 기반에서 문서와 문서 벡터간의 크기에 기반한 유사도 지표(예를 들어 유클리드 거리 기반 지표)는 정확도가 떨어지기 쉽다. 또한 문서가 매우 긴 경우 단어의 빈도수도 더 많을 것이기 때문에 이러한 빈도수에만 기반해서는 공정한 비교를 할 수 없다. 예를 들어 A문서에서 머신러닝이라는 단어가 5번 언급되고 B문서에서는 3번 언급됐을 때 A문서가 머신러닝과 더 밀접하게 관련된 문서라고 쉽게 판단해서는 안 된다. A문서가 B문서보다 10이상 크다면 오히려 B문서가 머신러닝이라는 토픽과 더 밀접하게 관련된 문서라고 판단할 수 있다.</p>
<p>간단한 문서에 대해서 서로 간의 문서 유사도를 코사인 유사도 기반으로 구해보자. 먼저 두개의 넘파이 배열에 대한 코사인 유사도를 구하는 cos_similarity() 함수를 작성해보자</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">cos_similarity</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">):</span>
    <span class="n">dot_product</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">)</span>
    <span class="n">l2_norm</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">v1</span><span class="p">)))</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">v2</span><span class="p">))))</span>
    <span class="n">similarity</span> <span class="o">=</span> <span class="n">dot_product</span> <span class="o">/</span> <span class="n">l2_norm</span>     
    
    <span class="k">return</span> <span class="n">similarity</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>doc_list로 정의된 3개의 간단한 문서의 유사도를 비교하기 위해 이 문서를 TF-IDF로 벡터화된 행렬로 변환한다. </li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>

<span class="n">doc_list</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;if you take the blue pill, the story ends&#39;</span> <span class="p">,</span>
            <span class="s1">&#39;if you take the red pill, you stay in Wonderland&#39;</span><span class="p">,</span>
            <span class="s1">&#39;if you take the red pill, I show you how deep the rabbit hole goes&#39;</span><span class="p">]</span>

<span class="n">tfidf_vect_simple</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">()</span>
<span class="n">feature_vect_simple</span> <span class="o">=</span> <span class="n">tfidf_vect_simple</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">doc_list</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">feature_vect_simple</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(3, 18)
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>반환된 행렬은 희소 행렬이므로 앞에서 작성한 cos_similarity() 함수의 인자인 array로 만들기 위해 밀집 행렬로 변환한 뒤 다시 각각을 배열로 변환한다. </li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">feature_vect_dense</span> <span class="o">=</span> <span class="n">feature_vect_simple</span><span class="o">.</span><span class="n">todense</span><span class="p">()</span>

<span class="c1">#첫번째 문장과 두번째 문장의 feature vector  추출</span>
<span class="n">vect1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">feature_vect_dense</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,)</span>
<span class="n">vect2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">feature_vect_dense</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,)</span>

<span class="c1">#첫번째 문장과 두번째 문장의 feature vector로 두개 문장의 Cosine 유사도 추출</span>
<span class="n">similarity_simple</span> <span class="o">=</span> <span class="n">cos_similarity</span><span class="p">(</span><span class="n">vect1</span><span class="p">,</span> <span class="n">vect2</span> <span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;문장 1, 문장 2 Cosine 유사도: </span><span class="si">{0:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">similarity_simple</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>문장 1, 문장 2 Cosine 유사도: 0.402
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>첫 번째 문장과 두 번째 문장의 코사인 유사도는 0.402이다. 다음으로 첫 번째 문장과 세 번째 문장, 그리고 두 번째 문장과 세 번째 문장의 유사도로 측정해보자</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vect1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">feature_vect_dense</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,)</span>
<span class="n">vect3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">feature_vect_dense</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,)</span>
<span class="n">similarity_simple</span> <span class="o">=</span> <span class="n">cos_similarity</span><span class="p">(</span><span class="n">vect1</span><span class="p">,</span> <span class="n">vect3</span> <span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;문장 1, 문장 3 Cosine 유사도: </span><span class="si">{0:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">similarity_simple</span><span class="p">))</span>

<span class="n">vect2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">feature_vect_dense</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,)</span>
<span class="n">vect3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">feature_vect_dense</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,)</span>
<span class="n">similarity_simple</span> <span class="o">=</span> <span class="n">cos_similarity</span><span class="p">(</span><span class="n">vect2</span><span class="p">,</span> <span class="n">vect3</span> <span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;문장 2, 문장 3 Cosine 유사도: </span><span class="si">{0:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">similarity_simple</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>문장 1, 문장 3 Cosine 유사도: 0.404
문장 2, 문장 3 Cosine 유사도: 0.456
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>사이킷런은 코사인 유사도를 측정하기 위해 sklearn.metrics.pairwise.cosine_similarity API를 제공한다.ㅏ </li>
<li>이번에는 이를 이용해 앞 예제의 문서 유사도를 측정해보자. </li>
<li>cosine_similarity()는 희소 행렬, 밀집 행렬 모두가 가능하며, 행렬 또는 배열 모두 가능하다. </li>
<li>앞서 만든 cos_similarity() 함수와 같이 별도의 변환 작업이 필요하지 않다. </li>
<li>첫 번째 문서와 비교해 바로 자신 문서인 첫 번째 문서, 그리고 두 번째, 세 번째 문서의 유사도를 측정해보자</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>

<span class="n">similarity_simple_pair</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">feature_vect_simple</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="p">,</span> <span class="n">feature_vect_simple</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">similarity_simple_pair</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[[1.         0.40207758 0.40425045]]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>여기서 값 1은 비교 기준은 첫 번째 문서 자신에 대한 유사도 측정이다.(feature_vect[1:]로 무시할 수 있다.)</li>
<li>cosine_similarity()는 쌍으로 코사인 유사도 값을 제공할 수 있다. </li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">similarity_simple_pair</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">feature_vect_simple</span> <span class="p">,</span> <span class="n">feature_vect_simple</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">similarity_simple_pair</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;shape:&#39;</span><span class="p">,</span><span class="n">similarity_simple_pair</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[[1.         0.40207758 0.40425045]
 [0.40207758 1.         0.45647296]
 [0.40425045 0.45647296 1.        ]]
shape: (3, 3)
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Opinion Review 데이터 세트를 이용한 문서 유사도 측정</li>
<li>앞 절의 문서 군집화에서 사용한 Opinion Review 데이터 세트를 이용해 이들 문서 간의 유사도를 측정해보자. </li>
<li>다시 데이터 세트를 새롭게 DataFrame으로 로드하고 문서 군집화를 적용해보자</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">nltk.stem</span> <span class="kn">import</span> <span class="n">WordNetLemmatizer</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">string</span>

<span class="n">remove_punct_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="nb">ord</span><span class="p">(</span><span class="n">punct</span><span class="p">),</span> <span class="kc">None</span><span class="p">)</span> <span class="k">for</span> <span class="n">punct</span> <span class="ow">in</span> <span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">)</span>
<span class="n">lemmar</span> <span class="o">=</span> <span class="n">WordNetLemmatizer</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">LemTokens</span><span class="p">(</span><span class="n">tokens</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">lemmar</span><span class="o">.</span><span class="n">lemmatize</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">LemNormalize</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">LemTokens</span><span class="p">(</span><span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">translate</span><span class="p">(</span><span class="n">remove_punct_dict</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">glob</span> <span class="o">,</span><span class="nn">os</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>

<span class="n">path</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">&#39;C:\Users\ehfus\Downloads\OpinosisDataset1.0\OpinosisDataset1.0\topics&#39;</span>
<span class="n">all_files</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;*.data&quot;</span><span class="p">))</span>     
<span class="n">filename_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">opinion_text</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">file_</span> <span class="ow">in</span> <span class="n">all_files</span><span class="p">:</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="n">file_</span><span class="p">,</span><span class="n">index_col</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;latin1&#39;</span><span class="p">)</span>
    <span class="n">filename_</span> <span class="o">=</span> <span class="n">file_</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\\</span><span class="s1">&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">filename</span> <span class="o">=</span> <span class="n">filename_</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">filename_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
    <span class="n">opinion_text</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">to_string</span><span class="p">())</span>

<span class="n">document_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;filename&#39;</span><span class="p">:</span><span class="n">filename_list</span><span class="p">,</span> <span class="s1">&#39;opinion_text&#39;</span><span class="p">:</span><span class="n">opinion_text</span><span class="p">})</span>

<span class="n">tfidf_vect</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">LemNormalize</span><span class="p">,</span> <span class="n">stop_words</span><span class="o">=</span><span class="s1">&#39;english&#39;</span> <span class="p">,</span> \
                             <span class="n">ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">min_df</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">max_df</span><span class="o">=</span><span class="mf">0.85</span> <span class="p">)</span>
<span class="n">feature_vect</span> <span class="o">=</span> <span class="n">tfidf_vect</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">document_df</span><span class="p">[</span><span class="s1">&#39;opinion_text&#39;</span><span class="p">])</span>

<span class="n">km_cluster</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">km_cluster</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">feature_vect</span><span class="p">)</span>
<span class="n">cluster_label</span> <span class="o">=</span> <span class="n">km_cluster</span><span class="o">.</span><span class="n">labels_</span>
<span class="n">cluster_centers</span> <span class="o">=</span> <span class="n">km_cluster</span><span class="o">.</span><span class="n">cluster_centers_</span>
<span class="n">document_df</span><span class="p">[</span><span class="s1">&#39;cluster_label&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cluster_label</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\ehfus\Anaconda3\envs\dv2021\lib\site-packages\sklearn\feature_extraction\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [&#39;ha&#39;, &#39;le&#39;, &#39;u&#39;, &#39;wa&#39;] not in stop_words.
  warnings.warn(&#39;Your stop_words may be inconsistent with &#39;
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>이전 절에서 해당 문서의 군집화는 전자제품, 호텔, 자동차를 주제로 군집화됐다. 이 중 호텔을 주제로 군집화된 문서를 이용해 특정 문서와 다른 문서 간의 유사도를 알아보자.</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>

<span class="c1"># cluster_label=1인 데이터는 호텔로 클러스터링된 데이터임. DataFrame에서 해당 Index를 추출</span>
<span class="n">hotel_indexes</span> <span class="o">=</span> <span class="n">document_df</span><span class="p">[</span><span class="n">document_df</span><span class="p">[</span><span class="s1">&#39;cluster_label&#39;</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">index</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;호텔로 클러스터링 된 문서들의 DataFrame Index:&#39;</span><span class="p">,</span> <span class="n">hotel_indexes</span><span class="p">)</span>

<span class="c1"># 호텔로 클러스터링된 데이터 중 첫번째 문서를 추출하여 파일명 표시.  </span>
<span class="n">comparison_docname</span> <span class="o">=</span> <span class="n">document_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">hotel_indexes</span><span class="p">[</span><span class="mi">0</span><span class="p">]][</span><span class="s1">&#39;filename&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;##### 비교 기준 문서명 &#39;</span><span class="p">,</span><span class="n">comparison_docname</span><span class="p">,</span><span class="s1">&#39; 와 타 문서 유사도######&#39;</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39; document_df에서 추출한 Index 객체를 feature_vect로 입력하여 호텔 클러스터링된 feature_vect 추출 </span>
<span class="sd">이를 이용하여 호텔로 클러스터링된 문서 중 첫번째 문서와 다른 문서간의 코사인 유사도 측정.&#39;&#39;&#39;</span>
<span class="n">similarity_pair</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">feature_vect</span><span class="p">[</span><span class="n">hotel_indexes</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="p">,</span> <span class="n">feature_vect</span><span class="p">[</span><span class="n">hotel_indexes</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">similarity_pair</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>호텔로 클러스터링 된 문서들의 DataFrame Index: Int64Index([1, 13, 14, 15, 20, 21, 24, 28, 30, 31, 32, 38, 39, 40, 45, 46], dtype=&#39;int64&#39;)
##### 비교 기준 문서명  bathroom_bestwestern_hotel_sfo  와 타 문서 유사도######
[[1.         0.0430688  0.05221059 0.06189595 0.05846178 0.06193118
  0.03638665 0.11742762 0.38038865 0.32619948 0.51442299 0.11282857
  0.13989623 0.1386783  0.09518068 0.07049362]]
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="c1"># argsort()를 이용하여 앞예제의 첫번째 문서와 타 문서간 유사도가 큰 순으로 정렬한 인덱스 반환하되 자기 자신은 제외. </span>
<span class="n">sorted_index</span> <span class="o">=</span> <span class="n">similarity_pair</span><span class="o">.</span><span class="n">argsort</span><span class="p">()[:,::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">sorted_index</span> <span class="o">=</span> <span class="n">sorted_index</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sorted_index</span><span class="p">)</span>

<span class="c1"># 유사도가 큰 순으로 hotel_indexes를 추출하여 재 정렬. </span>
<span class="nb">print</span><span class="p">(</span><span class="n">hotel_indexes</span><span class="p">)</span>
<span class="n">hotel_sorted_indexes</span> <span class="o">=</span> <span class="n">hotel_indexes</span><span class="p">[</span><span class="n">sorted_index</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,)]</span>

<span class="c1"># 유사도가 큰 순으로 유사도 값을 재정렬하되 자기 자신은 제외</span>
<span class="n">hotel_1_sim_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">similarity_pair</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,))[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">hotel_1_sim_value</span> <span class="o">=</span> <span class="n">hotel_1_sim_value</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>

<span class="c1"># 유사도가 큰 순으로 정렬된 Index와 유사도값을 이용하여 파일명과 유사도값을 Seaborn 막대 그래프로 시각화</span>
<span class="n">hotel_1_sim_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">hotel_1_sim_df</span><span class="p">[</span><span class="s1">&#39;filename&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">document_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">hotel_sorted_indexes</span><span class="p">][</span><span class="s1">&#39;filename&#39;</span><span class="p">]</span>
<span class="n">hotel_1_sim_df</span><span class="p">[</span><span class="s1">&#39;similarity&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">hotel_1_sim_value</span>

<span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;similarity&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;filename&#39;</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">hotel_1_sim_df</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">comparison_docname</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[[10  8  9 12 13  7 11 14 15  5  3  4  2  1  6]]
Int64Index([1, 13, 14, 15, 20, 21, 24, 28, 30, 31, 32, 38, 39, 40, 45, 46], dtype=&#39;int64&#39;)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Text(0.5, 1.0, &#39;bathroom_bestwestern_hotel_sfo&#39;)</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
" />
</div>

</div>

</div>
</div>

</div>
    

</div>



  </div><a class="u-url" href="/INTROml/2022/01/22/intro.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/INTROml/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/INTROml/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/INTROml/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/rhkrehtjd" target="_blank" title="rhkrehtjd"><svg class="svg-icon grey"><use xlink:href="/INTROml/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
