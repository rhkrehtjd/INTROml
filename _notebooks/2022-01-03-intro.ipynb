{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dfce513-5d24-4da0-947c-4bece7f88273",
   "metadata": {},
   "source": [
    "# 2022/01/03/MON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e84ca3f-6867-45b4-b35e-696270dc4daa",
   "metadata": {},
   "source": [
    "> `평가 process에 대해 알아보자`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73b2c79-2fee-4181-8f15-8d8da585f86e",
   "metadata": {},
   "source": [
    "### - `정확도 ?` = 예측 결과가 동일한 데이터 건수 / 전체 예측 데이터 건수\n",
    "    - 이진 부류의 경우 데이터 구성에 따라 ML 모델의 성능을 왜곡할 수 있기 때문에 정확도 수치 하나만 가지고 성능을 평가하는 건 위험함\n",
    "    - 그 예를 살펴보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0433e16a-1690-4fa0-a824-e71b11e7cf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "import numpy as np\n",
    "\n",
    "class MyDummyClassifier(BaseEstimator):\n",
    "    # fit 메서드는 아무것도 학습하지 않음\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    # predict() 메서드는 단순히 Sex feature 1이면 0 그렇지 않으면 1로 예측함\n",
    "    def predict(self, X):\n",
    "        pred = np.zeros((X.shape[0],1))\n",
    "        for i in range(X.shape[0]) :\n",
    "            if X['Sex'].iloc[i]==1 : \n",
    "                pred[i]=0\n",
    "            else :\n",
    "                pred[i]=1\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abba587-f548-4037-bdf2-421ff8000f38",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 원본 데이터를 재로딩, 데이터 가공, 학습 데이터/테스트 데이터 분할\n",
    "titanic_df= pd.read_csv('C:/Users/ehfus/Downloads/titanic/train.csv')\n",
    "y_titanic_df=titanic_df['Survived']\n",
    "X_titanic_df=titanic_df.drop('Survived',axis=1)\n",
    "X_titanic_df=transform_features(X_titanic_df) # transform_features 함수 정의 안 했기 때문에 에러 발생(140p)\n",
    "x_train,X_test,y_train,y_test = train_test_split(X_titanic_df, y_titanic_df,test_size=.2,random_state=0)\n",
    "\n",
    "# 위에서 생성한 Dummy Classifier를 이용해 학습/예측/평가 수행\n",
    "myclf=MydummyClassifier()\n",
    "myclf.fit(X_train,y_train)\n",
    "\n",
    "mypredictions=myclf.predict(X_train,y_train)\n",
    "\n",
    "mypredictions = myclf.predict(X_test)\n",
    "print('Dummy Classifier의 정확도는: {0:.4f}'.format(accuracy_score(y_test,mypredictions)))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e759e58-40aa-4cea-ba7d-4191cac0b455",
   "metadata": {},
   "source": [
    "Dummy Classifier의 정확도는 0.7877정도 나온다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536e2be3-17bc-49dc-b119-4f99e82abad2",
   "metadata": {},
   "source": [
    "즉 이렇게 단순한 알고리즘으로 예측을 하더라도 데이터의 구성에 따라 정확도의 결과는 약 78%정도로 높은 수치가 나올 수 있음. 따라서 정확도를 지표로 사용할 때는 매우 신중해야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ca81b7-d884-4faa-8eed-6c0dafcdefc6",
   "metadata": {},
   "source": [
    "***특히 불균형한 레이블 값 분포에서 ML 모델의 성능을 판단할 경우 적합한 평가 지표가 아님, 예를 들어보자***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2be817e7-791d-43c2-bcee-b0f720ae2e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 테스트 세트 크기:  (450,)\n",
      "테스트 세트 레이블 0과 1의 분포도\n",
      "0    405\n",
      "1     45\n",
      "dtype: int64\n",
      "모든 예측을 0으로 하여도 정확도는:0.900\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class MyFakeClassifier(BaseEstimator):\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    # 입력값으로 들어오는 X 데이터 세트의 크기만큼 모두 0값으로 만들어서 반환\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X),1),dtype=bool)\n",
    "\n",
    "# 사이킷런의 내장 데이터 세트인 load_digits()를 이용해 MNIST 데이터 로딩\n",
    "digits = load_digits()\n",
    "\n",
    "# digits 번호가 7번이면 True이고 이를 astype(int)로 1로 변환, 7번이 아니면 Fasle이고 0으로 변환.\n",
    "y=(digits.target==7).astype(int)\n",
    "X_train,X_test,y_train,y_test= train_test_split(digits.data,y,random_state=11)\n",
    "\n",
    "# 불균형한 레이블 데이터 분포도 확인\n",
    "print('레이블 테스트 세트 크기: ',y_test.shape)\n",
    "print('테스트 세트 레이블 0과 1의 분포도')\n",
    "print(pd.Series(y_test).value_counts())\n",
    "\n",
    "# Dummy Classifier로 학습/예측/정확도 평가\n",
    "fakeclf=MyFakeClassifier()\n",
    "fakeclf.fit(X_train,y_train)\n",
    "fakepred=fakeclf.predict(X_test)\n",
    "print('모든 예측을 0으로 하여도 정확도는:{:.3f}'.format(accuracy_score(y_test,fakepred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaf4f36-e648-4f78-b64a-2104d9a8d8ef",
   "metadata": {},
   "source": [
    "- 이처럼 정확도 평가 지표는 불균형한 레이블 데이터 세트에서는 성능 수치로 사용 되어서는 안 된다. 여러가지 분류 지표와 함께 이용하자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af117b9-01f2-4ca9-979d-6996f5aded25",
   "metadata": {},
   "source": [
    "### - `오차행렬 또는 혼동행렬 ?` \n",
    "    - 학습된 분류 모델이 예측을 수행하면서 얼마나 헷갈리고 있는지도 함께 보여주는 지표\n",
    "    - TN,FP,FN,TP로 나뉘며, 앞문자는 예측값과 실제값이 '같은가/ 틀린가'를 의미, 뒤 문자는 예측 결과 값이 부정(0)/긍정(1)을 의미\n",
    "    - 이 값을 조합해 정확도, 정밀도, 재현율 값을 알 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fe4c676-fc3a-49c6-b8d8-2936d28df457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[405,   0],\n",
       "       [ 45,   0]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 오차행렬 구하는 API\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, fakepred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708380c1-1a2c-4ad5-99f5-d21da9f510df",
   "metadata": {},
   "source": [
    "- TN은 405개, FN은 45개이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18294ee4-204d-4097-ae71-579bd63285b4",
   "metadata": {},
   "source": [
    "- 정확도 = 예측 결과와 실제 값이 동일한 건수/전체 데이터 수 = (TN + TP) / (TN + FP + FN + TP)\n",
    "- 정밀도 = TP / (FP + TP)\n",
    "- 재현율 = TP = (FN + TP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f13a04-60b9-4065-b816-0fbab3042c58",
   "metadata": {},
   "source": [
    "(158p 참고)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71674b5d-59f2-41a0-a07f-f1a49c1e78b6",
   "metadata": {},
   "source": [
    "분류하려는 업무의 특성상 정밀도 또는 재현율이 특별히 강조되어야 할 경우 분류의 결정 임계값(Threshold)을 조정해 정밀도 또는 재현율의 수치를 높일 수 있다.\n",
    "\n",
    "개별 데이터 별로 예측 확률을 반환하는 메서드 = predict_proba()\n",
    "predict_proba() 메서드는 학습이 완료된 사이킷런 Classifier 객체에서 호출이 가능하며 테스트 feature 데이터 세트를 파라미터로 입력해주면 테스트 feature 레코드의 개별 클래스 예측 확률을 반환함. predict() 메서드와 유사하지만 단지 반환 결과가 예측 결과 클래스값이 아닌 예측 확률 결과이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c37f5f-e821-450e-be61-b25e9dba2693",
   "metadata": {},
   "source": [
    "(160p 참고)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1420e55-6270-4d27-9138-00ef122f231c",
   "metadata": {},
   "source": [
    "- threshold 값을 조정해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "532ca3b9-76c9-49a2-92d4-11398ee08d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "X=[[1,-1,2],\n",
    "  [2,0,0],\n",
    "  [0,1.1,1.2]]\n",
    "\n",
    "# X의 개별 원소들이 threshold 값보다 같거나 작으면 0을 크면 1을 반환\n",
    "binarizer = Binarizer(threshold=1.1)\n",
    "print(binarizer.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d937af-2aac-4408-b8c4-42ad47130d08",
   "metadata": {},
   "source": [
    "이제 이 Binarizer를 이용해 사이킷런 predict()의 의사(pseudo)코드를 만들어보자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ca74a6-d2fb-4245-8c6b-7a1711f67b3c",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "# Binarizer의 threshold 설정값, 즉 분류 결정 임계값임.\n",
    "custom_threshold=0.5\n",
    "\n",
    "# predict_proba() 반환값의 두 번째 칼럼, 즉 Positive 클래스 칼럼 하나만 추출해 Binirizer를 적용\n",
    "pred_proba_1=pred_proba[:,1].reshape(-1,1)\n",
    "\n",
    "binarizer = Binarizer(threshold=cistom_threshold).fit(pred_proba_1)\n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test, custom_predict)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd458018-1cdc-4f4b-a1b8-514cc388c335",
   "metadata": {},
   "source": [
    "이때 threshold 설정값을 0.4로 설정, 즉 분류 결정 임계값을 낮추면 True값이 많아질 것이고 재현율 값이 올라가고 정밀도는 떨어질 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb38eb48-b7be-43cf-8c84-097f42905930",
   "metadata": {},
   "source": [
    "임계값을 0.4에서부터 0.6까지 0.05씩 증가시키며 평가 지표를 조사해보자, 이를 위해 get_eval_by_threshold() 함수를 만듦"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e339b3f-d0c8-4833-a971-1b79e1fe3b85",
   "metadata": {},
   "source": [
    "```python\n",
    "# 테스트를 수행할 모든 임계값을 리스트 객체로 저장\n",
    "thresholds = [0.4,0.45,0.5,0.55,0.6]\n",
    "\n",
    "def get_eval_by_threshold(y_test,pred_proba_c1,thresholds):\n",
    "    # thresholds list 객체 내의 값을 차례로 iteration하면서 Evaluation 수행.\n",
    "    for custom_threshold in thresholds:\n",
    "        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1)\n",
    "        custom_threshold = binarizer.transform(pres_proba_c1)\n",
    "        print('임계값:',custom_threshold)\n",
    "        get_clf_eval(y_test,custom_predict)\n",
    "get_eval_by_threshold(y_test,pred_proba[:,1].reshapep(-1,1), thresholds)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df13a5fb-849e-4971-a2a8-25fa41aea1af",
   "metadata": {},
   "source": [
    "- 임계값의 변경은 업무 환경에 맞게 두 개의 수치를 상호 보완할 수 있는 수준에서 적용돼야 한다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
