{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bf34e4c-3a63-4f4a-aa67-7e1a5daf62a7",
   "metadata": {},
   "source": [
    "# 2022/01/01/SAT(HappyNewYear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b599534-1228-4c4c-a5c8-18f7c0ec6773",
   "metadata": {},
   "source": [
    "datail-review 해보자\n",
    "\n",
    "- feature_names = 높이,가로 길이 이런 것들, data = 각 featuredml 값들, target = 0,1,2...예를 들면 붓꽃의 이름을 대용한 것, target_names = 각 target이 가리키는 이름이 무엇인지?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8a4284-b230-42c3-972e-7523a6df99b4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48234d7d-225b-43de-9a90-abd038e18118",
   "metadata": {},
   "source": [
    "model_selection 모듈은 학습 데이터와 테스트 데이터 세트를 분리하거나 교차 검증 분할 및 평가, 그리고 Estimator의 하이퍼 파라미터를 튜닝하기 위한 다양한 함수와 클래스를 제공, 전체 데이터를 학습 데이터와 테스트 데이터 세트로 분리해주는 train_test_split()부터 살펴보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c625c0dd-9efc-44d9-8cac-06b20e0c8c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측도:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "iris=load_iris() # 붓꽃 데이터 세트 로딩\n",
    "dt_clf=DecisionTreeClassifier()\n",
    "train_data=iris.data # 데이터 세트에서 feature만으로 구성된 데이터가 ndarray\n",
    "train_label=iris.target # 데이터 세트에서 label 데이터\n",
    "dt_clf.fit(train_data, train_label) # 학습 수행중\n",
    "pred=dt_clf.predict(train_data) # 예측 수행중 // 그런데 학습때 사용했던 train_data를 사용했음 -> 예측도 1 나올 것\n",
    "print('예측도: ',accuracy_score(train_label,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3d50de-e74d-4c2e-bb73-e35e8a080717",
   "metadata": {},
   "source": [
    "- 정확도가 100% 나왔음 $\\to$ 이미 학습한 학습 데이터 세트를 기반으로 예측했기 때문. 답을 알고 있는데 같은 문제를 낸 것이나 마찬가지\n",
    "- 따라서 예측을 수행하는 데이터 세트는 학습을 수행한 학습용 데이터 세트가 아닌 전용의 테스트 데이터 세트여야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82c96020-6781-40b0-9ab2-5f398cb321d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5806411-1be3-4509-a4f0-6aadf4539402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 0.9556\n"
     ]
    }
   ],
   "source": [
    "dt_clf=DecisionTreeClassifier()\n",
    "iris=load_iris()\n",
    "# train_test_split()의 반환값은 튜플 형태이다. 순차적으로 네가지 요소들을 반환한다\n",
    "X_train,X_test,y_train,y_test=train_test_split(iris.data, iris.target,test_size=0.3,random_state=121)\n",
    "dt_clf.fit(X_train,y_train)\n",
    "pred = dt_clf.predict(X_test)\n",
    "print('예측 정확도: {:.4f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a832e92-d7da-433f-9dae-c8a8783e2e63",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e28850-950c-46fa-8de3-3ab87b1ce12f",
   "metadata": {},
   "source": [
    "지금까지의 방법은 모델이 학습 데이터에만 과도하게 최적화되어, 실제 예측을 다른 데이터로 수행할 경우에는 예측 성능이 과도하게 떨어지는 `과적합`이 발생할 수 있다. 즉 해당 테스트 데이터에만 과적합되는 학습 모델이 만들어져 다른 테스트용 데이터가들어올 경우에는 성능이 저하된다. $\\to$ 개선하기 위해 `교차검증`을 이용해 다양한 학습과 평가를 수행해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da18158-85eb-4cf1-8f9c-9acdd7e82058",
   "metadata": {},
   "source": [
    "> 교차검증?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850d261a-2366-4905-9143-fa4a355c6c1c",
   "metadata": {},
   "source": [
    ": 본고사 치르기 전, 여러 모의고사를 치르는 것. 즉 본고사가 테스트 데이터 세트에 대해 평가하는 것이라면 모의고사는 교차 검증에서 많은 학습과 검증 세트에서 알고리즘 학습과 평가를 수행하는 것."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d24b86f-d9c4-4160-8dad-c2c7555215aa",
   "metadata": {},
   "source": [
    ": 학습 데이터 세트를 검증 데이터 세트와 학습 데이터 세트로 분할하여 수행한 뒤, 모든 학습/검증 과정이 완료된 후 최종적으로 성능을 평가하기 위해 테스트 데이터 세트를 마련함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad13625-665a-4596-987f-1428317bf3c8",
   "metadata": {},
   "source": [
    "> K fold 교차 검증?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2724f27-688b-48cc-bd6c-45def50737a1",
   "metadata": {},
   "source": [
    ": K개의 데이터 폴드 세트를 만들어서 K번만큼 각 폴드 세트에 학습과 검증, 평가를 반복적으로 수행 / 개괄적 과정은 교재 104 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736ae1bd-baf1-46dc-8c6b-0fda995e5288",
   "metadata": {},
   "source": [
    "- 실습해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d196b8c-d0b0-435c-87c8-cfc846c13448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "534415ff-f36a-4fc1-8316-9d0c7aaebad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트 크기: 150\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold # 위에서는 trian_test_split을 import했었음\n",
    "iris=load_iris() # 붓꽃 데이터 세트 로딩\n",
    "features=iris.data\n",
    "label=iris.target\n",
    "dt_clf=DecisionTreeClassifier(random_state=156)\n",
    "kfold=KFold(n_splits=5) # KFold 객체 생성\n",
    "cv_accuracy=[] # fold set별 정확도를 담을 리스트 객체 생성\n",
    "print('붓꽃 데이터 세트 크기:',features.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a29a3d-9917-4954-802b-5990b57e7267",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbe84ad-19ee-4c2b-9afe-4e42c7be5169",
   "metadata": {},
   "source": [
    "```python\n",
    "kfold=KFold(n_splits=5)\n",
    "```\n",
    "로 KFold객체를 생성했으니 객체의 split()을 호출해 전체 붓꽃 데이터를 5개의 fold 데이터 세트로 분리하자. 붓꽃 데이터 세트 크기가 150개니 120개는 학습용, 30개는 검증 테스트 데이터 세트이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5996bc72-7975-46ca-a469-dc14995e45ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차 검증 정확도 :1.0, 학습 데이터 크기 :120, 검증 데이터 크기 :30\n",
      "#1 검증 세트 인덱스:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "#2 교차 검증 정확도 :0.9667, 학습 데이터 크기 :120, 검증 데이터 크기 :30\n",
      "#2 검증 세트 인덱스:[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "\n",
      "#3 교차 검증 정확도 :0.8667, 학습 데이터 크기 :120, 검증 데이터 크기 :30\n",
      "#3 검증 세트 인덱스:[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "\n",
      "#4 교차 검증 정확도 :0.9333, 학습 데이터 크기 :120, 검증 데이터 크기 :30\n",
      "#4 검증 세트 인덱스:[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "\n",
      "#5 교차 검증 정확도 :0.7333, 학습 데이터 크기 :120, 검증 데이터 크기 :30\n",
      "#5 검증 세트 인덱스:[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      " *Conclusion* 평균 검증 정확도: 0.9\n"
     ]
    }
   ],
   "source": [
    "n_iter=0\n",
    "for train_index,test_index in kfold.split(features):\n",
    "    # kfold.split()으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터 추출\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    # 학습 및 예측\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    n_iter+=1\n",
    "    # 반복 시마다 정확도 측정\n",
    "    accuracy = np.round(accuracy_score(y_test,pred),4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기 :{2}, 검증 데이터 크기 :{3}'.format(n_iter,accuracy,train_size,test_size))\n",
    "    print('#{0} 검증 세트 인덱스:{1}'.format(n_iter, test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "# 개별 iteration별 정확도를 합하여 평균 정확도 계산\n",
    "print('\\n *Conclusion* 평균 검증 정확도:', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e96f2a6-a5fa-44b1-8c1f-2c9e6826b5c4",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa75d6d8-1552-43ec-940d-08caebeb4b4e",
   "metadata": {},
   "source": [
    "- 교차 검증시마다 검증 세트의 인덱스가 달라짐을 알 수 있다. \n",
    "\n",
    "- 검증세트 인덱스를 살펴보면 104p에서 설명한 그림의 설명과 유사함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22d378a-e9a1-4b82-a7c1-95ed98fa3924",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f261cec1-0cee-445b-b66e-c732e8e71616",
   "metadata": {},
   "source": [
    "> Stratified K 폴드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99292877-9002-4adc-a198-ba6901d7acad",
   "metadata": {},
   "source": [
    ": 불균형한 분포도를가진 레이블(결정 클래스) 데이터 집합을 위한 K 폴드 방식이다. 불균형한 분포도를 가진 레이블 데이터 집합은 특정 레이블 값이 특이하게 많거나 또는 적어서 분포가 한쪽으로 치우치는 것을 말함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3272a80a-d74f-41cf-8315-04c88e2b57ff",
   "metadata": {},
   "source": [
    "가령 대출 사기 데이터를 예측한다고 가정해보자, 이 데이터 세트는 1억건이고 수십개의 feature와 대출 사기 여부를 뜻하는 label(정상 대출0, 대출사기 : 1)로 구성돼 있다. K폴드로 랜덤하게 학습 및 테스트 세트의 인덱스를 고르더라도 레이블 값인 0과1의 비율을 제대로 반영하지 못하게 됨. 따라서 원본 데이터와 유사한 대출 사기 레이블 값의 분포를 학습/테스트 세트에도 유지하는 게 매우 중요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bec279-0dd0-4613-ba2c-2bb2ad31e544",
   "metadata": {},
   "source": [
    "- ***Stratified K 폴드는 이처럼 K폴드가 레이블 데이터 집합이 원본 데이터 집합의 레이블 분포를 학습 및 테스트 세트에 제대로 분배하지 못하는 경우의 문제를 해결해줌***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91996a25-4b66-42a4-815a-fbaf3936c9fb",
   "metadata": {},
   "source": [
    "붓꽃 데이터 세트를 DataFrame으로 생성하고 레이블 값의 분포도를 먼저 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1190a5d1-6ed9-4a0d-a49d-8d4d2c569d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    50\n",
      "1    50\n",
      "2    50\n",
      "Name: label, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "iris=load_iris()\n",
    "iris_df=pd.DataFrame(data=iris.data,columns=iris.feature_names)\n",
    "iris_df['label']=iris.target\n",
    "print(iris_df['label'].value_counts(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7a62c8-2720-4400-a5d0-f26f7462c6f9",
   "metadata": {},
   "source": [
    "- label값은 모두 50개로 분배되어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "217099cd-3500-410a-9dcd-a60ecea9be60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차 검증: 1\n",
      "학습 레이블 데이터 분포:\n",
      " 1    50\n",
      "2    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 0    50\n",
      "Name: label, dtype: int64\n",
      "------------------------------------------------------\n",
      "## 교차 검증: 2\n",
      "학습 레이블 데이터 분포:\n",
      " 0    50\n",
      "2    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 1    50\n",
      "Name: label, dtype: int64\n",
      "------------------------------------------------------\n",
      "## 교차 검증: 3\n",
      "학습 레이블 데이터 분포:\n",
      " 0    50\n",
      "1    50\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 2    50\n",
      "Name: label, dtype: int64\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "kfold=KFold(n_splits=3)\n",
    "n_iter=0\n",
    "for train_index, test_index in kfold.split(iris_df):\n",
    "    n_iter+=1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test=iris_df['label'].iloc[test_index]\n",
    "    print('## 교차 검증: {}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts())\n",
    "    print('------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7fc61f-e5e0-4b7c-b071-2b2bd52c947a",
   "metadata": {},
   "source": [
    "- 교차 검증 시마다 3개의 폴드 세트로 만들어지는 학습 레이블과 검증 레이블이 완전히 다른 값으로 추출되었다. 예를 들어 첫번째 교차 검증에서는 학습 레이블의 1,2값이 각각 50개가 추출되었고 검증 레이블의 0값이 50개 추출되었음, 즉 학습레이블은 1,2 밖에 없으므로 0의 경우는 전혀 학습하지 못함. 반대로 검증 레이블은 0밖에 없으므로 학습 모델은 절대 0을 예측하지 못함. 이런 유형으로 교차 검증 데이터 세트를 분할하면 검증 예측 정확도는 0이 될 수밖에 없다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5522f10-91ee-4cba-88e9-848ff96dec32",
   "metadata": {},
   "source": [
    "- StratifiedKFold는 이렇게 KFold로 분할된 레이블 데이터 세트가 전체 레이블 값의 분포도를 반영하지 못하는 문제를 해결함. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7d07f3-78c5-4621-b1f5-94438608502e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d219c4c2-622f-4f26-be62-a9102eceac3b",
   "metadata": {},
   "source": [
    "실습해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e718e79-7b35-4b82-85cf-e97bf442dca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차검증: 1\n",
      "학습 레이블 데이터 분포: \n",
      " 2    34\n",
      "0    33\n",
      "1    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포: \n",
      " 0    17\n",
      "1    17\n",
      "2    16\n",
      "Name: label, dtype: int64\n",
      "--------------------------------------------------------\n",
      "## 교차검증: 2\n",
      "학습 레이블 데이터 분포: \n",
      " 1    34\n",
      "0    33\n",
      "2    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포: \n",
      " 0    17\n",
      "2    17\n",
      "1    16\n",
      "Name: label, dtype: int64\n",
      "--------------------------------------------------------\n",
      "## 교차검증: 3\n",
      "학습 레이블 데이터 분포: \n",
      " 0    34\n",
      "1    33\n",
      "2    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포: \n",
      " 1    17\n",
      "2    17\n",
      "0    16\n",
      "Name: label, dtype: int64\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf=StratifiedKFold(n_splits=3)\n",
    "n_iter=0\n",
    "\n",
    "# split 메소드에 인자로 feature데이터 세트뿐만 아니라 레이블 데이터 세트도 반드시 넣어줘야함\n",
    "for train_index,test_index in skf.split(iris_df,iris_df['label']):\n",
    "    n_iter+=1\n",
    "    label_train=iris_df['label'].iloc[train_index]\n",
    "    label_test=iris_df['label'].iloc[test_index]\n",
    "    print('## 교차검증: {}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포: \\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포: \\n', label_test.value_counts())\n",
    "    print('--------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a08a353-e86d-40ba-8adb-c071d521d567",
   "metadata": {},
   "source": [
    "- 학습 레이블과 검증 레이블 데이터 값의 분포도가 동일하게 할당됐음을 알 수 있다. 이렇게 분할이 되어야 레이블 값 0,1,2를 모두 학습할 수 있고 이에 기반해 검증을 수행할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e82a63-a8e8-4098-8f0a-8b6730600933",
   "metadata": {},
   "source": [
    "- 이제 StratifiedKFold를 이용해 붓꽃 데이터를 교차 검증해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a62868c-1489-4a37-b83f-e2ac1d3118eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#4 교차 검증 정확도 : 0.92, 학습 데이터 크기 : 100, 검증 데이터 크기 : 50\n",
      "#4 검증 세트 인덱스: [ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
      "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "## 교차 검증별 정확도: [0.92]\n",
      "## 평균 검증 정확도: 0.92\n",
      "\n",
      "#5 교차 검증 정확도 : 0.92, 학습 데이터 크기 : 100, 검증 데이터 크기 : 50\n",
      "#5 검증 세트 인덱스: [ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
      "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "## 교차 검증별 정확도: [0.92 0.92]\n",
      "## 평균 검증 정확도: 0.92\n",
      "\n",
      "#6 교차 검증 정확도 : 0.92, 학습 데이터 크기 : 100, 검증 데이터 크기 : 50\n",
      "#6 검증 세트 인덱스: [ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
      "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "## 교차 검증별 정확도: [0.92 0.92 0.92]\n",
      "## 평균 검증 정확도: 0.92\n"
     ]
    }
   ],
   "source": [
    "df_clf=DecisionTreeClassifier(random_state=156)\n",
    "skfold=StratifiedKFold(n_splits=3)\n",
    "n_iter=3\n",
    "cv_accuracy=[]\n",
    "\n",
    "# StratifiedKFol의 split() 호출시 반드시 레이블 데이터 세트도 추가 입력 필요\n",
    "for train_index, test_ondex in skfold.split(features, label):\n",
    "    # split()으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터 추출\n",
    "    X_train,X_test=features[train_index],features[test_index]\n",
    "    y_train,y_test=label[train_index], label[test_index]\n",
    "    # 학습 및 예측\n",
    "    df_clf.fit(X_train,y_train)\n",
    "    pred=dt_clf.predict(X_test)\n",
    "    # 반복시마다 정확도 측정\n",
    "    n_iter+=1\n",
    "    accuracy=np.around(accuracy_score(y_test,pred),4)\n",
    "    train_size=X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print('\\n#{} 교차 검증 정확도 : {}, 학습 데이터 크기 : {}, 검증 데이터 크기 : {}'.format(n_iter,accuracy,train_size,test_size))\n",
    "    print('#{} 검증 세트 인덱스: {}'.format(n_iter, test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "    # 교차 검증별 정확도 및 평균 정확도 계산\n",
    "    print('\\n## 교차 검증별 정확도:', np.around(cv_accuracy,4))\n",
    "    print('## 평균 검증 정확도:',np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c18d155-9a56-446b-a040-b975e54113e9",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ae50a7-8917-41d4-9a79-92167bbcf4b5",
   "metadata": {},
   "source": [
    "> ### ***`교차 검증을 보다 간편하게 - cross_val_score()`***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6bc5c119-b55e-46bb-bc55-8eafa032dea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도:  [0.98 0.94 0.98]\n",
      "평균 검증 정확도:  0.9667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score,cross_validate\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data=load_iris()\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "data= iris_data.data\n",
    "label=iris_data.target\n",
    "\n",
    "# 성능 지표는 정확도 (accuracy), 교차 검증 세트는 3개\n",
    "scores = cross_val_score(dt_clf, data, label, scoring='accuracy', cv=3)\n",
    "print('교차 검증별 정확도: ',np.round(scores,4))\n",
    "print('평균 검증 정확도: ',np.round(np.mean(scores),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814813db-ff96-4c65-9077-adf8bed8e52d",
   "metadata": {},
   "source": [
    "- cv로 지정된 횟수만큼 scoring 파라미터로 지정된 평가지표로 평가 결과값을 배열로 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ec11ae-82c2-4939-8809-29d4b0349cf8",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcc14ec-f443-4967-bddc-abf24f96d6e0",
   "metadata": {},
   "source": [
    "> ### ***`GridSearchCV - 교차 검증과 최적 하이퍼 파라미터 튜닝을 동시에`***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8fa3a6-414f-4e19-8263-7e032846979c",
   "metadata": {},
   "source": [
    "- 하이퍼 파라미터? 머신러닝 알고리즘을 구성하는 주요 구성 요소이며, 이 값을 조정해 알고리즘의 예측 성능을 개선할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f263b105-6ef4-4b0e-8566-5d5f205eb2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0              0.700                0.7               0.70  \n",
       "1              0.700                0.7               0.70  \n",
       "2              0.925                1.0               0.95  \n",
       "3              0.925                1.0               0.95  \n",
       "4              0.975                1.0               0.95  \n",
       "5              0.975                1.0               0.95  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 데이터를 로딩하고 학습 데이터와 테스트 데이터 분리\n",
    "iris_data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data,iris_data.target, test_size=0.2, random_state=121)\n",
    "dtree= DecisionTreeClassifier()\n",
    "\n",
    "# 파라미터를 딕셔너리 형태로 설정\n",
    "parameters = {'max_depth' : [1,2,3], 'min_samples_split' : [2,3]}\n",
    "\n",
    "import pandas as pd\n",
    "# param_grid의 하이퍼 파라미터를 3개의 train, test set fold로 나누어 테스트 수행 설정\n",
    "# rifit=True가 default이며, 이때 가장 젛은 파라미터 설정으로 재학습시킴\n",
    "grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True)\n",
    "# 붓꽃 학습 데이터로 param_grid의 하이퍼 파라미터를 순차적으로 학습/평가\n",
    "grid_dtree.fit(X_train,y_train)\n",
    "#GridSearchCV 결과를 추출해 DataFrame으로 변환\n",
    "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df[['params','mean_test_score','rank_test_score','split0_test_score','split1_test_score','split2_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "462a8a7d-ef56-4455-8cc7-4da305a75582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터: {'max_depth': 3, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 정확도:0.975000\n"
     ]
    }
   ],
   "source": [
    "print('GridSearchCV 최적 파라미터:', grid_dtree.best_params_)\n",
    "print('GridSearchCV 최고 정확도:{:4f}'.format(grid_dtree.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913895ff-cd3d-4e3c-a06a-a78a03c0fb09",
   "metadata": {},
   "source": [
    "- 인덱스 4,5rk rank_test_score가 1인 것으로 보아 공동 1위이며 예측 성능 1등을 의미함. \n",
    "- 열 4,5,6은 cv=3 이라서 열2는 그 세개의 평균을 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "06edbf13-ed9c-4fda-b31c-53669ea85cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 세트 정확도: 0.9667\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV의 refit으로 이미 학습된 estimator 반환\n",
    "estimator = grid_dtree.best_estimator_\n",
    "# GridSearchCV의 best_estimator_는 이미 최적 학습이 됐으므로 별도 학습이 필요없음\n",
    "pred = estimator.predict(X_test)\n",
    "print('테스트 데이터 세트 정확도: {:.4f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e66c088-a94d-4135-9d6b-b95ac554c843",
   "metadata": {},
   "source": [
    "- 일반적으로 학습 데이터를 GridSearchCV를 이용해 최적 하이퍼 파라미터 튜닝을 수행한 뒤에 별도의 테스트 세트에서 이를 평가하는 것이 일반적인 머신 러닝 모델 적용 방법이다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
